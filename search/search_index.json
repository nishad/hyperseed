{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Hyperseed","text":"<p>Hyperseed is an experimental Python tool for hyperspectral seed image analysis. Analyze hyperspectral imagery of plant seeds to extract spectral signatures with automatic calibration, intelligent segmentation, and comprehensive visualizations.</p> <p>Research Foundation</p> <p>Inspired by Reddy, et al. 2023, Sensors</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p> ENVI Format Support</p> <p>Read and process ENVI format hyperspectral data from Specim SWIR cameras</p> </li> <li> <p> Automatic Calibration</p> <p>White/dark reference correction with automatic bad pixel interpolation</p> </li> <li> <p> Intelligent Outlier Removal</p> <p>Automatically detect and remove reference objects, calibration targets, and anomalies</p> </li> <li> <p> Advanced Preprocessing</p> <p>Multiple spectral preprocessing methods: SNV, derivatives, baseline correction, and more</p> </li> <li> <p> Smart Segmentation</p> <p>Multiple algorithms for accurate seed detection and isolation</p> </li> <li> <p> Spectral Extraction</p> <p>Extract average spectral signatures from individual seeds with spatial preservation</p> </li> <li> <p> Comprehensive Visualizations</p> <p>Auto-generate distribution, segmentation, and spectral plots</p> </li> <li> <p> Batch Processing</p> <p>Process multiple datasets efficiently</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started with Hyperseed in minutes:</p> InstallationBasic UsageBatch Processing <pre><code>pip install hyperseed\n</code></pre> <pre><code># Analyze a single dataset\nhyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --export-plots\n</code></pre> <pre><code># Process multiple datasets\nhyperseed batch dataset/ \\\n    --output-dir results/ \\\n    --min-pixels 50\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python: 3.10 or higher</li> <li>RAM: 8GB+ recommended</li> </ul>"},{"location":"#processing-pipeline","title":"Processing Pipeline","text":"<pre><code>graph LR\n    A[ENVI Data] --&gt; B[Calibration]\n    B --&gt; C[Preprocessing]\n    C --&gt; D[Segmentation]\n    D --&gt; E[Validation]\n    E --&gt; F[Outlier Removal]\n    F --&gt; G[Spectral Extraction]\n    G --&gt; H[Export Results]</code></pre> <ol> <li>Data Loading: Read ENVI format hyperspectral data</li> <li>Calibration: Apply white/dark reference correction with bad pixel interpolation</li> <li>Preprocessing: Apply spectral preprocessing methods</li> <li>Segmentation: Detect and isolate individual seeds</li> <li>Validation: Filter seeds based on size and shape criteria</li> <li>Outlier Removal: Automatically remove reference objects and anomalies</li> <li>Extraction: Extract average spectrum for each valid seed</li> <li>Export: Save results with comprehensive information</li> </ol>"},{"location":"#output-examples","title":"Output Examples","text":""},{"location":"#csv-spectra-file","title":"CSV Spectra File","text":"<pre><code>seed_id,index,centroid_y,centroid_x,area,eccentricity,solidity,band_1000nm,band_1005nm,...\n1,0,234.5,156.2,435,0.34,0.92,0.234,0.237,...\n2,1,345.6,234.1,421,0.28,0.94,0.229,0.232,...\n</code></pre>"},{"location":"#visualization-plots","title":"Visualization Plots","text":"<p>When using <code>--export-plots</code>, Hyperseed generates:</p> <ul> <li>Distribution Plot: Spatial and area distribution of seeds</li> <li>Segmentation Plot: Numbered seed visualization with boundaries</li> <li>Spectra Plot: Individual and mean spectral curves</li> <li>Statistics Plot: Statistical analysis of spectral variability</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Quick Start Guide</p> <p>Learn the basics in 5 minutes with a step-by-step tutorial</p> </li> <li> <p> User Guide</p> <p>Comprehensive documentation for all features and workflows</p> </li> <li> <p> CLI Reference</p> <p>Detailed command-line interface documentation</p> </li> <li> <p> API Reference</p> <p>Python API documentation for advanced users</p> </li> </ul>"},{"location":"#development-status","title":"Development Status","text":"<p>Alpha Release</p> <p>Hyperseed is currently in alpha (v0.1.0-alpha.3). The API may change between releases. See the changelog for version history.</p>"},{"location":"#license","title":"License","text":"<p>Hyperseed is released under the MIT License.</p>"},{"location":"#credits","title":"Credits","text":"<p>Logo icon \"Sprouting Seed\" by 4urbrand from The Noun Project, used under Creative Commons license.</p>"},{"location":"about/changelog/","title":"Changelog","text":"<p>All notable changes to the Hyperseed project.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"about/changelog/#010-alpha3-2025-01-29","title":"0.1.0-alpha.3 - 2025-01-29","text":""},{"location":"about/changelog/#added","title":"Added","text":"<ul> <li>Initial release of Hyperseed - Hyperspectral Seed Image Analysis Tool</li> <li>Core functionality for hyperspectral image processing and analysis</li> <li>Support for ENVI format hyperspectral data files</li> <li>Comprehensive preprocessing pipeline with multiple methods:</li> <li>Standard Normal Variate (SNV)</li> <li>Smoothing (Savitzky-Golay, Gaussian, Moving Average, Median)</li> <li>Baseline correction (Polynomial, Rubberband, ASLS)</li> <li>Derivative computation (1<sup>st</sup>, 2<sup>nd</sup> order)</li> <li>Normalization (Min-Max, Max, Area, Vector, Peak)</li> <li>Multiplicative Scatter Correction (MSC)</li> <li>Detrending</li> <li>Advanced segmentation algorithms for seed detection:</li> <li>Threshold-based segmentation (Otsu, adaptive, manual)</li> <li>Watershed segmentation</li> <li>Connected components analysis</li> <li>Combined approach for robust detection</li> <li>Spectral extraction and analysis capabilities:</li> <li>Extract mean spectra from segmented regions</li> <li>Statistical analysis of spectral signatures</li> <li>Export to CSV and HDF5 formats</li> <li>Reflectance calibration with white and dark references</li> <li>Command-line interface (CLI) with multiple commands:</li> <li><code>analyze</code>: Full pipeline analysis</li> <li><code>segment</code>: Segmentation only</li> <li><code>batch</code>: Batch processing</li> <li><code>config</code>: Configuration management</li> <li><code>info</code>: System information</li> <li>Comprehensive test suite with ~80% code coverage</li> <li>Visualization tools for segmentation results</li> <li>Support for batch processing of multiple datasets</li> <li>Configuration system with presets (minimal, standard, advanced)</li> <li>Validation metrics for segmentation quality (IoU, Dice, F1-score)</li> </ul>"},{"location":"about/changelog/#features","title":"Features","text":"<ul> <li>Performance: Optimized for large hyperspectral datasets</li> <li>Flexibility: Modular architecture allowing custom pipelines</li> <li>Extensibility: Plugin-ready architecture for custom algorithms</li> <li>Documentation: Comprehensive documentation and examples</li> <li>Testing: Extensive test coverage ensuring reliability</li> </ul>"},{"location":"about/changelog/#dependencies","title":"Dependencies","text":"<ul> <li>Python &gt;=3.10</li> <li>NumPy, SciPy, scikit-learn, scikit-image</li> <li>OpenCV for image processing</li> <li>Pandas for data manipulation</li> <li>Matplotlib for visualization</li> <li>Click for CLI interface</li> <li>Rich for enhanced terminal output</li> </ul>"},{"location":"about/changelog/#known-issues","title":"Known Issues","text":"<ul> <li>Some empty module directories reserved for future features</li> <li>Visualization requires display environment (not suitable for headless servers without proper configuration)</li> </ul>"},{"location":"about/changelog/#contributors","title":"Contributors","text":"<ul> <li>Nishad Thalhath - Lead Developer</li> <li>Deepa Kasaragod - Contributor</li> </ul>"},{"location":"about/changelog/#note","title":"Note","text":"<p>This is an alpha release (alpha.3). The API and features are still under active development and may change in future releases.</p>"},{"location":"about/license/","title":"License","text":"<p>Hyperseed is released under the MIT License.</p>"},{"location":"about/license/#mit-license","title":"MIT License","text":"<p>Copyright \u00a9 2025 Hyperseed Contributors</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"about/license/#what-this-means","title":"What This Means","text":"<p>The MIT License is a permissive license that allows you to:</p> <ul> <li>\u2705 Use the software for any purpose (commercial or non-commercial)</li> <li>\u2705 Modify the source code</li> <li>\u2705 Distribute copies of the software</li> <li>\u2705 Include the software in proprietary projects</li> </ul> <p>Requirements: - Include the original license and copyright notice - Provide attribution to the original authors</p> <p>Limitations: - The software is provided \"as is\" without warranty - Authors are not liable for damages</p>"},{"location":"about/license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>Hyperseed depends on open-source libraries, each with their own licenses:</p> Library License NumPy BSD-3-Clause SciPy BSD-3-Clause scikit-learn BSD-3-Clause scikit-image BSD-3-Clause Matplotlib PSF-based Pandas BSD-3-Clause OpenCV Apache 2.0 Click BSD-3-Clause <p>See each library's documentation for complete license information.</p>"},{"location":"about/license/#contributors","title":"Contributors","text":"<p>All contributors to Hyperseed are listed on the GitHub Contributors page.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Python API documentation for Hyperseed.</p>"},{"location":"api-reference/#overview","title":"Overview","text":"<p>Hyperseed provides a Python API for programmatic control of the hyperspectral analysis pipeline. This allows you to:</p> <ul> <li>Integrate Hyperseed into your own workflows</li> <li>Customize processing beyond CLI capabilities</li> <li>Build custom applications using Hyperseed components</li> </ul>"},{"location":"api-reference/#modules","title":"Modules","text":"<ul> <li> <p>Core Modules</p> <p>Core functionality and base classes</p> </li> <li> <p>I/O Operations</p> <p>ENVI file reading and data loading</p> </li> <li> <p>Calibration</p> <p>Reflectance calibration with white/dark references</p> </li> <li> <p>Preprocessing</p> <p>Spectral preprocessing methods</p> </li> <li> <p>Segmentation</p> <p>Seed detection and isolation algorithms</p> </li> <li> <p>Extraction</p> <p>Spectral signature extraction</p> </li> </ul>"},{"location":"api-reference/#quick-start-example","title":"Quick Start Example","text":"<pre><code>from hyperseed import ENVIReader, Settings\nfrom hyperseed.core.calibration import ReflectanceCalibrator\nfrom hyperseed.core.preprocessing import PreprocessingPipeline\nfrom hyperseed.core.segmentation import SeedSegmenter\nfrom hyperseed.core.extraction import SpectralExtractor\n\n# Load data\nreader = ENVIReader(\"path/to/data.hdr\")\ndata = reader.read_data()\nwavelengths = reader.get_wavelengths()\n\n# Calibrate (automatically handles bad pixel correction)\ncalibrator = ReflectanceCalibrator(clip_negative=True, clip_max=1.0)\ncalibrated, reader = calibrator.calibrate_from_directory(\"path/to/dataset\")\n\n# Preprocess\nsettings = Settings()\npreprocessor = PreprocessingPipeline(settings.preprocessing)\nprocessed = preprocessor.fit_transform(calibrated)\n\n# Segment\nsegmenter = SeedSegmenter(settings.segmentation)\nmask, n_seeds = segmenter.segment(processed)\n\n# Extract spectra\nextractor = SpectralExtractor()\nresults = extractor.extract(calibrated, mask, wavelengths)\n\n# Save results\nextractor.save_csv(\"results.csv\")\n</code></pre>"},{"location":"api-reference/#installation-for-api-use","title":"Installation for API Use","text":"<pre><code># Install from PyPI\npip install hyperseed\n\n# Or from source for development\ngit clone https://github.com/nishad/hyperseed\ncd hyperseed\npip install -e \".[dev]\"\n</code></pre>"},{"location":"api-reference/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>Hyperseed works great in Jupyter notebooks for interactive analysis:</p> <pre><code># In Jupyter\nimport hyperseed\nfrom hyperseed import ENVIReader\n\n# Load and visualize\nreader = ENVIReader(\"data.hdr\")\ndata = reader.read_data()\n\n# Plot RGB composite\nimport matplotlib.pyplot as plt\nrgb = data[:, :, [100, 50, 10]]  # Select R, G, B bands\nplt.imshow(rgb)\n</code></pre>"},{"location":"api-reference/#next-steps","title":"Next Steps","text":"<p>Explore detailed API documentation for each module:</p> <ul> <li>Core: Base classes and utilities</li> <li>I/O: Data loading and ENVI format handling</li> <li>Calibration: Reflectance calibration</li> <li>Preprocessing: Spectral preprocessing</li> <li>Segmentation: Seed segmentation</li> <li>Extraction: Spectral extraction</li> </ul>"},{"location":"api-reference/calibration/","title":"Calibration","text":"<p>Reflectance calibration with white and dark references.</p>"},{"location":"api-reference/calibration/#reflectancecalibrator","title":"ReflectanceCalibrator","text":"<p>The ReflectanceCalibrator class applies reflectance calibration.</p> <pre><code>from hyperseed.core.calibration.reflectance import ReflectanceCalibrator\n\n# Create calibrator\ncalibrator = ReflectanceCalibrator(\n    clip_negative=True,\n    clip_max=1.0\n)\n\n# Calibrate data\ncalibrated_data, reader = calibrator.calibrate_from_directory(\"path/to/dataset\")\n</code></pre>"},{"location":"api-reference/calibration/#methods","title":"Methods","text":"<code>__init__(clip_negative, clip_max)</code> Initialize calibrator with settings <code>calibrate(data, white_ref, dark_ref)</code> Calibrate using references <code>calibrate_from_directory(dataset_path)</code> Load and calibrate from directory <p>Full API documentation coming soon. For now, use Python's built-in help:</p> <pre><code>from hyperseed.core.calibration.reflectance import ReflectanceCalibrator\nhelp(ReflectanceCalibrator)\n</code></pre>"},{"location":"api-reference/core/","title":"Core Modules","text":"<p>Core functionality and base classes for Hyperseed.</p>"},{"location":"api-reference/core/#settings","title":"Settings","text":"<p>The Settings class provides configuration management for Hyperseed's analysis pipeline.</p> <pre><code>from hyperseed.config.settings import Settings\n\n# Create settings with defaults\nsettings = Settings()\n\n# Access configuration sections\ncalibration_config = settings.calibration\npreprocessing_config = settings.preprocessing\nsegmentation_config = settings.segmentation\n</code></pre> <p>See the Configuration Guide for detailed configuration options.</p>"},{"location":"api-reference/core/#module-documentation","title":"Module Documentation","text":"<p>Full API documentation coming soon. For now, use Python's built-in help:</p> <pre><code>import hyperseed\nhelp(hyperseed.config.settings.Settings)\n</code></pre>"},{"location":"api-reference/extraction/","title":"Extraction","text":"<p>Spectral signature extraction from segmented seeds.</p>"},{"location":"api-reference/extraction/#spectralextractor","title":"SpectralExtractor","text":"<p>The SpectralExtractor class extracts spectral signatures from segmented regions.</p> <pre><code>from hyperseed.core.extraction.extractor import SpectralExtractor\n\n# Create extractor\nextractor = SpectralExtractor()\n\n# Extract spectra\nresults = extractor.extract(\n    calibrated_data,\n    segmentation_mask,\n    wavelengths\n)\n\n# Save results\nextractor.save_csv(\"results.csv\")\nextractor.save_hdf5(\"results.h5\")\n</code></pre>"},{"location":"api-reference/extraction/#methods","title":"Methods","text":"<code>__init__()</code> Initialize extractor <code>extract(data, mask, wavelengths)</code> Extract spectral signatures from masked regions <code>save_csv(filepath)</code> Save results to CSV file <code>save_hdf5(filepath)</code> Save results to HDF5 file <p>Full API documentation coming soon. For now, use Python's built-in help:</p> <pre><code>from hyperseed.core.extraction.extractor import SpectralExtractor\nhelp(SpectralExtractor)\n</code></pre>"},{"location":"api-reference/io/","title":"I/O Operations","text":"<p>ENVI file reading and data loading.</p>"},{"location":"api-reference/io/#envireader","title":"ENVIReader","text":"<p>The ENVIReader class handles reading ENVI format hyperspectral data.</p> <pre><code>from hyperseed.core.io.envi_reader import ENVIReader\n\n# Load ENVI data\nreader = ENVIReader(\"path/to/data.hdr\")\ndata = reader.read_data()\nwavelengths = reader.get_wavelengths()\nmetadata = reader.get_metadata()\n</code></pre>"},{"location":"api-reference/io/#methods","title":"Methods","text":"<code>__init__(header_path)</code> Initialize reader with ENVI header file path <code>read_data()</code> Read the hyperspectral datacube <code>get_wavelengths()</code> Get wavelength list from header <code>get_metadata()</code> Get all metadata from header <p>Full API documentation coming soon. For now, use Python's built-in help:</p> <pre><code>from hyperseed.core.io.envi_reader import ENVIReader\nhelp(ENVIReader)\n</code></pre>"},{"location":"api-reference/preprocessing/","title":"Preprocessing API","text":"<p>Programmatic interface for spectral preprocessing.</p>"},{"location":"api-reference/preprocessing/#preprocessingpipeline","title":"PreprocessingPipeline","text":"<p>The <code>PreprocessingPipeline</code> class provides a complete preprocessing pipeline with configurable methods.</p>"},{"location":"api-reference/preprocessing/#basic-usage","title":"Basic Usage","text":"<pre><code>from hyperseed.core.preprocessing.pipeline import PreprocessingPipeline\nfrom hyperseed.config.settings import Settings\n\n# Create pipeline with default settings\nsettings = Settings()\npipeline = PreprocessingPipeline(settings.preprocessing)\n\n# Apply preprocessing\npreprocessed_data = pipeline.fit_transform(calibrated_data)\n</code></pre>"},{"location":"api-reference/preprocessing/#with-custom-configuration","title":"With Custom Configuration","text":"<pre><code>from hyperseed.config.settings import PreprocessingConfig\n\n# Create custom configuration\nconfig = PreprocessingConfig(\n    method=\"custom\",\n    snv=True,\n    smoothing=True,\n    smoothing_window=15,\n    smoothing_polyorder=3,\n    baseline_correction=True,\n    baseline_order=2,\n    derivative=1,\n    msc=False,\n    detrend=False\n)\n\n# Create pipeline\npipeline = PreprocessingPipeline(config)\n\n# Fit and transform\npreprocessed = pipeline.fit_transform(data)\n</code></pre>"},{"location":"api-reference/preprocessing/#methods","title":"Methods","text":""},{"location":"api-reference/preprocessing/#__init__config-preprocessingconfig","title":"<code>__init__(config: PreprocessingConfig)</code>","text":"<p>Initialize the preprocessing pipeline with configuration.</p> <p>Parameters: - <code>config</code>: PreprocessingConfig object with preprocessing settings</p> <p>Example: <pre><code>from hyperseed.config.settings import PreprocessingConfig\n\nconfig = PreprocessingConfig(method=\"standard\")\npipeline = PreprocessingPipeline(config)\n</code></pre></p>"},{"location":"api-reference/preprocessing/#fitdata-npndarray-preprocessingpipeline","title":"<code>fit(data: np.ndarray) -&gt; PreprocessingPipeline</code>","text":"<p>Fit the preprocessing pipeline on data (e.g., compute MSC reference spectrum).</p> <p>Parameters: - <code>data</code>: Hyperspectral data (Y, X, Bands) or (Samples, Bands)</p> <p>Returns: - Self (for method chaining)</p> <p>Example: <pre><code>pipeline.fit(training_data)\n</code></pre></p>"},{"location":"api-reference/preprocessing/#transformdata-npndarray-npndarray","title":"<code>transform(data: np.ndarray) -&gt; np.ndarray</code>","text":"<p>Apply preprocessing transformations to data.</p> <p>Parameters: - <code>data</code>: Hyperspectral data to transform</p> <p>Returns: - Preprocessed data with same shape as input</p> <p>Example: <pre><code>preprocessed = pipeline.transform(test_data)\n</code></pre></p> <p>Note: Must call <code>fit()</code> before <code>transform()</code> if using MSC.</p>"},{"location":"api-reference/preprocessing/#fit_transformdata-npndarray-npndarray","title":"<code>fit_transform(data: np.ndarray) -&gt; np.ndarray</code>","text":"<p>Fit the pipeline and transform data in one step.</p> <p>Parameters: - <code>data</code>: Hyperspectral data to fit and transform</p> <p>Returns: - Preprocessed data</p> <p>Example: <pre><code>preprocessed = pipeline.fit_transform(data)\n</code></pre></p> <p>This is equivalent to: <pre><code>pipeline.fit(data)\npreprocessed = pipeline.transform(data)\n</code></pre></p>"},{"location":"api-reference/preprocessing/#get_step_names-liststr","title":"<code>get_step_names() -&gt; list[str]</code>","text":"<p>Get list of enabled preprocessing steps.</p> <p>Returns: - List of step names that will be applied</p> <p>Example: <pre><code>steps = pipeline.get_step_names()\nprint(f\"Preprocessing steps: {', '.join(steps)}\")\n# Output: Preprocessing steps: SNV, Smoothing, Baseline Correction\n</code></pre></p>"},{"location":"api-reference/preprocessing/#describe-str","title":"<code>describe() -&gt; str</code>","text":"<p>Get human-readable description of the pipeline.</p> <p>Returns: - String describing the preprocessing configuration</p> <p>Example: <pre><code>print(pipeline.describe())\n# Output: Preprocessing Pipeline:\n#   - SNV: enabled\n#   - Smoothing: Savitzky-Golay (window=11, polyorder=3)\n#   - Baseline Correction: Polynomial (order=2)\n#   ...\n</code></pre></p>"},{"location":"api-reference/preprocessing/#individual-preprocessing-functions","title":"Individual Preprocessing Functions","text":"<p>For more control, use individual preprocessing functions from <code>hyperseed.core.preprocessing.methods</code>.</p>"},{"location":"api-reference/preprocessing/#apply_snv","title":"apply_snv","text":"<p>Standard Normal Variate transformation.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_snv\n\n# Apply SNV to spectra\nsnv_data = apply_snv(data, axis=-1)\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>axis</code>: Axis along which to apply SNV (default: -1)</p> <p>Returns: - SNV-transformed data</p>"},{"location":"api-reference/preprocessing/#apply_smoothing","title":"apply_smoothing","text":"<p>Smooth spectra using various methods.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_smoothing\n\n# Savitzky-Golay smoothing (default)\nsmoothed = apply_smoothing(\n    data,\n    window_length=11,\n    polyorder=3,\n    method=\"savgol\"\n)\n\n# Moving average\nsmoothed = apply_smoothing(\n    data,\n    window_length=11,\n    method=\"moving_average\"\n)\n\n# Gaussian filter\nsmoothed = apply_smoothing(\n    data,\n    window_length=11,\n    method=\"gaussian\"\n)\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>window_length</code>: Window size (must be odd) - <code>polyorder</code>: Polynomial order for Savitzky-Golay (default: 3) - <code>method</code>: \"savgol\", \"moving_average\", or \"gaussian\" (default: \"savgol\") - <code>axis</code>: Axis along which to smooth (default: -1)</p> <p>Returns: - Smoothed data</p>"},{"location":"api-reference/preprocessing/#apply_derivative","title":"apply_derivative","text":"<p>Compute spectral derivatives.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_derivative\n\n# First derivative\nfirst_deriv = apply_derivative(\n    data,\n    order=1,\n    window_length=11,\n    polyorder=3\n)\n\n# Second derivative\nsecond_deriv = apply_derivative(\n    data,\n    order=2,\n    window_length=11,\n    polyorder=3\n)\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>order</code>: Derivative order (1 or 2) - <code>window_length</code>: Window size for Savitzky-Golay (default: 11) - <code>polyorder</code>: Polynomial order (default: 3) - <code>axis</code>: Axis along which to compute (default: -1)</p> <p>Returns: - Derivative spectra</p>"},{"location":"api-reference/preprocessing/#apply_baseline_correction","title":"apply_baseline_correction","text":"<p>Remove baseline from spectra.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_baseline_correction\n\n# Polynomial baseline\ncorrected = apply_baseline_correction(\n    data,\n    order=2,\n    method=\"polynomial\"\n)\n\n# Rubberband baseline\ncorrected = apply_baseline_correction(\n    data,\n    method=\"rubberband\"\n)\n\n# ASLS baseline\ncorrected = apply_baseline_correction(\n    data,\n    method=\"asls\"\n)\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>order</code>: Polynomial order (for polynomial method, default: 2) - <code>method</code>: \"polynomial\", \"rubberband\", or \"asls\" (default: \"polynomial\") - <code>axis</code>: Axis along which to correct (default: -1)</p> <p>Returns: - Baseline-corrected data</p> <p>Methods: - polynomial: Fits polynomial and subtracts - rubberband: Convex hull method - asls: Asymmetric Least Squares (lam=1e6, p=0.01, niter=10)</p>"},{"location":"api-reference/preprocessing/#apply_msc","title":"apply_msc","text":"<p>Multiplicative Scatter Correction.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_msc\n\n# Use mean spectrum as reference\ncorrected = apply_msc(data)\n\n# Use custom reference\nreference = data[0, :]  # Use first spectrum\ncorrected = apply_msc(data, reference=reference)\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>reference</code>: Reference spectrum (if None, uses mean) - <code>axis</code>: Axis along which to apply (default: -1)</p> <p>Returns: - MSC-corrected data</p>"},{"location":"api-reference/preprocessing/#apply_detrend","title":"apply_detrend","text":"<p>Remove linear trends.</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_detrend\n\n# Linear detrending\ndetrended = apply_detrend(data, type=\"linear\")\n\n# Constant detrending (remove mean)\ndetrended = apply_detrend(data, type=\"constant\")\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>type</code>: \"linear\" or \"constant\" (default: \"linear\") - <code>axis</code>: Axis along which to detrend (default: -1)</p> <p>Returns: - Detrended data</p>"},{"location":"api-reference/preprocessing/#apply_normalization","title":"apply_normalization","text":"<p>Normalize spectra (not exposed in config, but available via API).</p> <pre><code>from hyperseed.core.preprocessing.methods import apply_normalization\n\n# Min-max normalization [0, 1]\nnormalized = apply_normalization(data, method=\"minmax\")\n\n# Max normalization\nnormalized = apply_normalization(data, method=\"max\")\n\n# Area normalization\nnormalized = apply_normalization(data, method=\"area\")\n\n# Vector (L2) normalization\nnormalized = apply_normalization(data, method=\"vector\")\n</code></pre> <p>Parameters: - <code>data</code>: Input array - <code>method</code>: \"minmax\", \"max\", \"area\", or \"vector\" (default: \"minmax\") - <code>axis</code>: Axis along which to normalize (default: -1)</p> <p>Returns: - Normalized data</p>"},{"location":"api-reference/preprocessing/#complete-example","title":"Complete Example","text":"<pre><code>import numpy as np\nfrom hyperseed.core.io.envi_reader import ENVIReader\nfrom hyperseed.core.calibration.reflectance import ReflectanceCalibrator\nfrom hyperseed.core.preprocessing.pipeline import PreprocessingPipeline\nfrom hyperseed.config.settings import PreprocessingConfig\n\n# Load data\nreader = ENVIReader(\"path/to/data.hdr\")\ndata = reader.read_data()\nwavelengths = reader.get_wavelengths()\n\n# Calibrate\ncalibrator = ReflectanceCalibrator(clip_negative=True, clip_max=1.0)\ncalibrated, _ = calibrator.calibrate_from_directory(\"path/to/dataset\")\n\n# Configure preprocessing\nconfig = PreprocessingConfig(\n    method=\"custom\",\n    snv=True,\n    smoothing=True,\n    smoothing_window=15,\n    baseline_correction=True,\n    derivative=1\n)\n\n# Preprocess\npipeline = PreprocessingPipeline(config)\npreprocessed = pipeline.fit_transform(calibrated)\n\nprint(f\"Original shape: {calibrated.shape}\")\nprint(f\"Preprocessed shape: {preprocessed.shape}\")\nprint(f\"Preprocessing steps: {', '.join(pipeline.get_step_names())}\")\n\n# Use preprocessed data for segmentation or analysis\n</code></pre>"},{"location":"api-reference/preprocessing/#using-individual-functions","title":"Using Individual Functions","text":"<pre><code>from hyperseed.core.preprocessing.methods import (\n    apply_snv,\n    apply_smoothing,\n    apply_baseline_correction,\n    apply_derivative\n)\n\n# Manual preprocessing pipeline\ndata_snv = apply_snv(calibrated, axis=-1)\ndata_smooth = apply_smoothing(data_snv, window_length=15, polyorder=3)\ndata_baseline = apply_baseline_correction(data_smooth, order=2)\ndata_deriv = apply_derivative(data_baseline, order=1)\n\n# Now use data_deriv for analysis\n</code></pre>"},{"location":"api-reference/preprocessing/#notes","title":"Notes","text":"<ul> <li>All preprocessing functions preserve data shape</li> <li>Operations are applied along the last axis by default (spectral axis)</li> <li>For hyperspectral cubes (Y, X, Bands), reshaping may be needed</li> <li>The PreprocessingPipeline handles reshaping automatically</li> <li>MSC requires fitting before transformation (computes reference spectrum)</li> <li>Normalization is available via API but not exposed in configuration</li> </ul>"},{"location":"api-reference/preprocessing/#see-also","title":"See Also","text":"<ul> <li>Preprocessing Guide: Detailed method descriptions</li> <li>Configuration: Configuration reference</li> <li>CLI Reference: Command-line preprocessing</li> </ul>"},{"location":"api-reference/segmentation/","title":"Segmentation API","text":"<p>Programmatic interface for seed detection and segmentation.</p>"},{"location":"api-reference/segmentation/#seedsegmenter","title":"SeedSegmenter","text":"<p>The <code>SeedSegmenter</code> class provides a unified interface for applying various segmentation algorithms with validation and visualization.</p>"},{"location":"api-reference/segmentation/#basic-usage","title":"Basic Usage","text":"<pre><code>from hyperseed.core.segmentation.segmenter import SeedSegmenter\nfrom hyperseed.config.settings import Settings\n\n# Create segmenter with default settings\nsettings = Settings()\nsegmenter = SeedSegmenter(settings.segmentation)\n\n# Segment seeds\nmask, n_seeds = segmenter.segment(preprocessed_data)\n\n# Get seed properties\nproperties = segmenter.get_seed_properties()\n</code></pre>"},{"location":"api-reference/segmentation/#with-custom-configuration","title":"With Custom Configuration","text":"<pre><code>from hyperseed.config.settings import SegmentationConfig\n\n# Create custom configuration\nconfig = SegmentationConfig(\n    algorithm=\"watershed\",\n    min_pixels=200,\n    max_pixels=5000,\n    reject_overlapping=True,\n    morphology_operations=True,\n    morphology_kernel_size=5,\n    remove_outliers=True,\n    outlier_min_area=75,\n    outlier_max_area=1800\n)\n\n# Create segmenter\nsegmenter = SeedSegmenter(config)\n\n# Segment\nmask, n_seeds = segmenter.segment(data)\n</code></pre>"},{"location":"api-reference/segmentation/#seedsegmenter-methods","title":"SeedSegmenter Methods","text":""},{"location":"api-reference/segmentation/#__init__config-optionalsegmentationconfig-none","title":"__init__(config: Optional[SegmentationConfig] = None)","text":"<p>Initialize the seed segmenter.</p> <p>Parameters: - <code>config</code> (SegmentationConfig, optional): Segmentation configuration object. If None, uses defaults.</p> <p>Example: <pre><code>from hyperseed.config.settings import SegmentationConfig\n\nconfig = SegmentationConfig(algorithm=\"watershed\", min_pixels=200)\nsegmenter = SeedSegmenter(config)\n</code></pre></p>"},{"location":"api-reference/segmentation/#segmentdata-npndarray-band_index-optionalint-none-validate-bool-true-tuplenpndarray-int","title":"segment(data: np.ndarray, band_index: Optional[int] = None, validate: bool = True) -&gt; Tuple[np.ndarray, int]","text":"<p>Perform seed segmentation on hyperspectral data.</p> <p>Parameters: - <code>data</code> (np.ndarray): Hyperspectral data array with shape (lines, samples, bands) or (lines, samples) - <code>band_index</code> (int, optional): Specific band to use for segmentation. If None, uses automatic selection based on variance - <code>validate</code> (bool, default: True): Whether to apply validation after segmentation (size filtering, overlap rejection)</p> <p>Returns: - <code>mask</code> (np.ndarray): Labeled mask array where each seed has a unique ID (0 = background) - <code>n_seeds</code> (int): Number of seeds detected</p> <p>Example: <pre><code># Segment using all bands (automatic selection)\nmask, n_seeds = segmenter.segment(data)\nprint(f\"Found {n_seeds} seeds\")\n\n# Segment using specific band\nmask, n_seeds = segmenter.segment(data, band_index=50)\n\n# Segment without validation\nmask, n_seeds = segmenter.segment(data, validate=False)\n</code></pre></p> <p>Note: The segmentation process includes: 1. Apply selected algorithm (threshold/watershed/connected/combined) 2. Apply morphological operations (if enabled) 3. Validate seeds (if validate=True): size filtering, overlap rejection 4. Filter border seeds (if enabled)</p>"},{"location":"api-reference/segmentation/#visualizedata-npndarray-band_index-optionalint-none-save_path-optionalunionstr-path-none-show_labels-bool-true-show_boundaries-bool-true-pltfigure","title":"visualize(data: np.ndarray, band_index: Optional[int] = None, save_path: Optional[Union[str, Path]] = None, show_labels: bool = True, show_boundaries: bool = True) -&gt; plt.Figure","text":"<p>Visualize segmentation results.</p> <p>Parameters: - <code>data</code> (np.ndarray): Original hyperspectral data - <code>band_index</code> (int, optional): Band to use for background image. If None, uses mean of middle bands - <code>save_path</code> (str or Path, optional): Path to save the figure. If None, displays interactive plot - <code>show_labels</code> (bool, default: True): Whether to show seed ID numbers - <code>show_boundaries</code> (bool, default: True): Whether to show seed boundaries</p> <p>Returns: - <code>fig</code> (matplotlib.figure.Figure): Matplotlib figure object</p> <p>Example: <pre><code># Visualize with all features\nfig = segmenter.visualize(data, show_labels=True, show_boundaries=True)\n\n# Save to file\nsegmenter.visualize(\n    data,\n    save_path=\"segmentation_result.png\",\n    band_index=50\n)\n\n# Simple visualization without labels\nfig = segmenter.visualize(data, show_labels=False)\nplt.show()\n</code></pre></p> <p>Visualization layout: - Left panel: Original image - Middle panel: Colored segmentation with numbered seeds - Right panel: Seed boundaries overlay</p>"},{"location":"api-reference/segmentation/#get_seed_properties-list","title":"get_seed_properties() -&gt; list","text":"<p>Get morphological properties of all segmented seeds.</p> <p>Returns: - <code>properties</code> (list of dict): List of property dictionaries, one per seed</p> <p>Property dictionary keys: - <code>label</code> (int): Seed ID - <code>area</code> (int): Seed area in pixels - <code>centroid</code> (tuple): (y, x) centroid coordinates - <code>bbox</code> (tuple): (min_row, min_col, max_row, max_col) bounding box - <code>eccentricity</code> (float): Elongation (0=circle, 1=line) - <code>solidity</code> (float): Area/convex_hull_area (shape regularity) - <code>coords</code> (np.ndarray): All pixel coordinates belonging to seed</p> <p>Example: <pre><code>properties = segmenter.get_seed_properties()\n\nfor prop in properties:\n    print(f\"Seed {prop['label']}:\")\n    print(f\"  Area: {prop['area']} pixels\")\n    print(f\"  Centroid: {prop['centroid']}\")\n    print(f\"  Eccentricity: {prop['eccentricity']:.3f}\")\n    print(f\"  Solidity: {prop['solidity']:.3f}\")\n</code></pre></p>"},{"location":"api-reference/segmentation/#get_validation_stats-optionaldictstr-any","title":"get_validation_stats() -&gt; Optional[Dict[str, Any]]","text":"<p>Get validation statistics from the last segmentation.</p> <p>Returns: - <code>stats</code> (dict or None): Validation statistics dictionary, or None if validation not performed</p> <p>Statistics dictionary keys: - <code>initial_count</code> (int): Number of seeds before validation - <code>final_count</code> (int): Number of seeds after validation - <code>removed_by_size</code> (int): Seeds removed by size filtering - <code>removed_by_overlap</code> (int): Seeds removed by overlap rejection - <code>removed_by_shape</code> (int): Seeds removed by shape criteria</p> <p>Example: <pre><code>mask, n_seeds = segmenter.segment(data, validate=True)\nstats = segmenter.get_validation_stats()\n\nif stats:\n    print(f\"Initial seeds: {stats['initial_count']}\")\n    print(f\"Final seeds: {stats['final_count']}\")\n    print(f\"Removed by size: {stats['removed_by_size']}\")\n    print(f\"Removed by overlap: {stats['removed_by_overlap']}\")\n</code></pre></p>"},{"location":"api-reference/segmentation/#export_maskpath-unionstr-path-format-str-npy-none","title":"export_mask(path: Union[str, Path], format: str = \"npy\") -&gt; None","text":"<p>Export segmentation mask to file.</p> <p>Parameters: - <code>path</code> (str or Path): Output file path - <code>format</code> (str, default: \"npy\"): Export format. Options: \"npy\", \"png\", \"tiff\"</p> <p>Example: <pre><code># Export as NumPy array (recommended)\nsegmenter.export_mask(\"results/mask.npy\", format=\"npy\")\n\n# Export as PNG image (scaled to 0-255)\nsegmenter.export_mask(\"results/mask.png\", format=\"png\")\n\n# Export as TIFF\nsegmenter.export_mask(\"results/mask.tiff\", format=\"tiff\")\n</code></pre></p> <p>Format details: - npy: Native NumPy format, preserves exact labels, recommended for further processing - png: 8-bit PNG, labels scaled to 0-255, useful for visualization - tiff: TIFF format, preserves labels</p>"},{"location":"api-reference/segmentation/#export_propertiespath-unionstr-path-format-str-csv-none","title":"export_properties(path: Union[str, Path], format: str = \"csv\") -&gt; None","text":"<p>Export seed properties to file.</p> <p>Parameters: - <code>path</code> (str or Path): Output file path - <code>format</code> (str, default: \"csv\"): Export format. Options: \"csv\", \"json\"</p> <p>Example: <pre><code># Export as CSV\nsegmenter.export_properties(\"results/seed_props.csv\", format=\"csv\")\n\n# Export as JSON\nsegmenter.export_properties(\"results/seed_props.json\", format=\"json\")\n</code></pre></p> <p>CSV format: Tabular format with columns for label, area, centroid_y, centroid_x, bbox, eccentricity, solidity</p> <p>JSON format: List of property dictionaries (excludes pixel coordinates)</p>"},{"location":"api-reference/segmentation/#describe-dictstr-any","title":"describe() -&gt; Dict[str, Any]","text":"<p>Get description of segmentation results.</p> <p>Returns: - <code>description</code> (dict): Dictionary describing the segmentation</p> <p>Description dictionary keys: - <code>algorithm</code> (str): Algorithm used - <code>n_seeds</code> (int): Number of seeds detected - <code>mask_shape</code> (tuple): Shape of segmentation mask - <code>config</code> (dict): Configuration parameters - <code>validation</code> (dict, optional): Validation statistics - <code>seed_statistics</code> (dict, optional): Area statistics (min, max, mean, std)</p> <p>Example: <pre><code>desc = segmenter.describe()\nprint(f\"Algorithm: {desc['algorithm']}\")\nprint(f\"Seeds detected: {desc['n_seeds']}\")\nprint(f\"Mask shape: {desc['mask_shape']}\")\n\nif 'seed_statistics' in desc:\n    stats = desc['seed_statistics']\n    print(f\"Area range: {stats['min_area']}-{stats['max_area']} pixels\")\n    print(f\"Mean area: {stats['mean_area']:.1f} pixels\")\n</code></pre></p>"},{"location":"api-reference/segmentation/#individual-segmentation-functions","title":"Individual Segmentation Functions","text":"<p>For advanced use, individual segmentation algorithms can be called directly.</p>"},{"location":"api-reference/segmentation/#threshold_segmentation","title":"threshold_segmentation","text":"<pre><code>from hyperseed.core.segmentation.algorithms import threshold_segmentation\n\nmask, n_seeds = threshold_segmentation(\n    data,\n    method=\"otsu\",  # or \"adaptive\", \"manual\"\n    threshold_value=None,  # for manual method only\n    min_seed_size=200,\n    max_seed_size=None,\n    band_index=None\n)\n</code></pre> <p>Parameters: - <code>data</code> (np.ndarray): Hyperspectral data - <code>method</code> (str): \"otsu\", \"adaptive\", or \"manual\" - <code>threshold_value</code> (float, optional): Manual threshold (for method=\"manual\") - <code>min_seed_size</code> (int, default: 200): Minimum seed size in pixels - <code>max_seed_size</code> (int, optional): Maximum seed size in pixels - <code>band_index</code> (int, optional): Specific band to use</p> <p>Returns: - <code>mask</code> (np.ndarray): Labeled mask - <code>n_seeds</code> (int): Number of seeds</p> <p>Methods: - otsu: Automatic global threshold using Otsu's method - adaptive: Local adaptive thresholding (block size=35) - manual: Requires explicit threshold_value parameter</p>"},{"location":"api-reference/segmentation/#watershed_segmentation","title":"watershed_segmentation","text":"<pre><code>from hyperseed.core.segmentation.algorithms import watershed_segmentation\n\nmask, n_seeds = watershed_segmentation(\n    data,\n    min_seed_size=200,\n    max_seed_size=None,\n    band_index=None,\n    min_distance=20\n)\n</code></pre> <p>Parameters: - <code>data</code> (np.ndarray): Hyperspectral data - <code>min_seed_size</code> (int, default: 200): Minimum seed size in pixels - <code>max_seed_size</code> (int, optional): Maximum seed size in pixels - <code>band_index</code> (int, optional): Specific band to use - <code>min_distance</code> (int, default: 20): Minimum distance between seed centers</p> <p>Returns: - <code>mask</code> (np.ndarray): Labeled mask - <code>n_seeds</code> (int): Number of seeds</p> <p>How it works: 1. Initial Otsu thresholding 2. Distance transform computation 3. Local maxima detection (seed centers) 4. Watershed algorithm to separate regions 5. Size filtering</p>"},{"location":"api-reference/segmentation/#connected_components_segmentation","title":"connected_components_segmentation","text":"<pre><code>from hyperseed.core.segmentation.algorithms import connected_components_segmentation\n\nmask, n_seeds = connected_components_segmentation(\n    data,\n    min_seed_size=200,\n    max_seed_size=None,\n    band_index=None,\n    connectivity=2\n)\n</code></pre> <p>Parameters: - <code>data</code> (np.ndarray): Hyperspectral data - <code>min_seed_size</code> (int, default: 200): Minimum seed size in pixels - <code>max_seed_size</code> (int, optional): Maximum seed size in pixels - <code>band_index</code> (int, optional): Specific band to use - <code>connectivity</code> (int, default: 2): Connectivity for labeling (1 or 2)</p> <p>Returns: - <code>mask</code> (np.ndarray): Labeled mask - <code>n_seeds</code> (int): Number of seeds</p> <p>How it works: 1. Otsu thresholding 2. Morphological cleanup (closing + opening) 3. Connected component labeling 4. Size filtering 5. Shape filtering (eccentricity &lt; 0.95, solidity &gt; 0.7)</p>"},{"location":"api-reference/segmentation/#combined_segmentation","title":"combined_segmentation","text":"<pre><code>from hyperseed.core.segmentation.algorithms import combined_segmentation\n\nmask, n_seeds = combined_segmentation(\n    data,\n    min_seed_size=200,\n    max_seed_size=None,\n    band_index=None,\n    methods=[\"threshold\", \"watershed\"]\n)\n</code></pre> <p>Parameters: - <code>data</code> (np.ndarray): Hyperspectral data - <code>min_seed_size</code> (int, default: 200): Minimum seed size in pixels - <code>max_seed_size</code> (int, optional): Maximum seed size in pixels - <code>band_index</code> (int, optional): Specific band to use - <code>methods</code> (list, default: [\"threshold\", \"watershed\"]): List of algorithms to combine</p> <p>Returns: - <code>mask</code> (np.ndarray): Labeled mask - <code>n_seeds</code> (int): Number of seeds</p> <p>How it works: 1. Runs each specified algorithm 2. Converts results to binary masks 3. Combines using majority voting (consensus threshold = ceil(n_methods/2)) 4. Labels final consensus mask 5. Size filtering</p>"},{"location":"api-reference/segmentation/#apply_morphological_operations","title":"apply_morphological_operations","text":"<pre><code>from hyperseed.core.segmentation.algorithms import apply_morphological_operations\n\ncleaned_mask = apply_morphological_operations(\n    mask,\n    operations=[\"closing\", \"opening\"],\n    kernel_size=3\n)\n</code></pre> <p>Parameters: - <code>mask</code> (np.ndarray): Binary or labeled mask - <code>operations</code> (list, default: [\"closing\", \"opening\"]): Operations to apply in order - <code>kernel_size</code> (int, default: 3): Size of morphological kernel (disk shape)</p> <p>Returns: - <code>cleaned_mask</code> (np.ndarray): Processed mask</p> <p>Available operations: - closing: Fills small holes (dilation \u2192 erosion) - opening: Removes small protrusions (erosion \u2192 dilation) - erosion: Shrinks objects - dilation: Expands objects</p>"},{"location":"api-reference/segmentation/#complete-example","title":"Complete Example","text":"<pre><code>import numpy as np\nfrom hyperseed.core.io.envi_reader import ENVIReader\nfrom hyperseed.core.calibration.reflectance import ReflectanceCalibrator\nfrom hyperseed.core.preprocessing.pipeline import PreprocessingPipeline\nfrom hyperseed.core.segmentation.segmenter import SeedSegmenter\nfrom hyperseed.config.settings import Settings, SegmentationConfig\n\n# Load data\nreader = ENVIReader(\"path/to/data.hdr\")\ndata = reader.read_data()\nwavelengths = reader.get_wavelengths()\n\n# Calibrate\ncalibrator = ReflectanceCalibrator(clip_negative=True, clip_max=1.0)\ncalibrated, reader = calibrator.calibrate_from_directory(\"path/to/dataset\")\n\n# Preprocess (minimal for segmentation)\nsettings = Settings()\nsettings.preprocessing.method = \"minimal\"\npreprocessor = PreprocessingPipeline(settings.preprocessing)\nprocessed = preprocessor.fit_transform(calibrated)\n\n# Configure segmentation\nseg_config = SegmentationConfig(\n    algorithm=\"watershed\",\n    min_pixels=200,\n    morphology_operations=True,\n    morphology_kernel_size=5,\n    filter_border_seeds=True,\n    remove_outliers=True,\n    outlier_min_area=75,\n    outlier_max_area=1800,\n    outlier_iqr_lower=1.5,\n    outlier_iqr_upper=3.0,\n    use_shape_filtering=True,\n    outlier_eccentricity=0.90,\n    outlier_solidity=0.75\n)\n\n# Segment\nsegmenter = SeedSegmenter(seg_config)\nmask, n_seeds = segmenter.segment(processed, validate=True)\n\nprint(f\"Segmented {n_seeds} seeds\")\n\n# Get properties\nproperties = segmenter.get_seed_properties()\nfor prop in properties[:5]:  # Show first 5\n    print(f\"Seed {prop['label']}: {prop['area']} pixels at {prop['centroid']}\")\n\n# Get validation stats\nstats = segmenter.get_validation_stats()\nif stats:\n    print(f\"\\nValidation:\")\n    print(f\"  Initial: {stats['initial_count']} seeds\")\n    print(f\"  Final: {stats['final_count']} seeds\")\n    print(f\"  Removed by size: {stats['removed_by_size']}\")\n\n# Visualize\nsegmenter.visualize(\n    calibrated,\n    save_path=\"segmentation_result.png\",\n    show_labels=True,\n    show_boundaries=True\n)\n\n# Export\nsegmenter.export_mask(\"segmentation_mask.npy\")\nsegmenter.export_properties(\"seed_properties.csv\")\n\n# Get description\ndesc = segmenter.describe()\nprint(f\"\\nDescription: {desc}\")\n</code></pre>"},{"location":"api-reference/segmentation/#see-also","title":"See Also","text":"<ul> <li>Segmentation Guide: Detailed algorithm descriptions and usage</li> <li>Configuration: Configuration reference</li> <li>CLI Reference: Command-line segmentation</li> </ul>"},{"location":"cli-reference/","title":"CLI Reference","text":"<p>Complete command-line interface reference for Hyperseed.</p>"},{"location":"cli-reference/#commands-overview","title":"Commands Overview","text":"<p>Hyperseed provides the following commands:</p> Command Purpose Documentation analyze Process single dataset Details \u2192 batch Process multiple datasets Details \u2192 segment Segmentation only Details \u2192 config Generate configuration Via <code>--help</code> info Show version/system info Via <code>--help</code>"},{"location":"cli-reference/#global-options","title":"Global Options","text":"<p>Options available for all commands:</p> <pre><code>--help              Show help message and exit\n--version           Show version and exit\n-v, --verbose       Enable verbose output\n-d, --debug         Enable debug mode\n</code></pre>"},{"location":"cli-reference/#getting-help","title":"Getting Help","text":"<p>Get help for any command:</p> <pre><code># General help\nhyperseed --help\n\n# Command-specific help\nhyperseed analyze --help\nhyperseed batch --help\nhyperseed segment --help\n</code></pre>"},{"location":"cli-reference/#quick-examples","title":"Quick Examples","text":""},{"location":"cli-reference/#analyze-a-single-dataset","title":"Analyze a Single Dataset","text":"<pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --export-plots\n</code></pre>"},{"location":"cli-reference/#batch-process-multiple-datasets","title":"Batch Process Multiple Datasets","text":"<pre><code>hyperseed batch dataset/ \\\n    --output-dir results/\n</code></pre>"},{"location":"cli-reference/#generate-configuration","title":"Generate Configuration","text":"<pre><code>hyperseed config --output my_config.yaml --preset minimal\n</code></pre>"},{"location":"cli-reference/#next-steps","title":"Next Steps","text":"<ul> <li> <p>analyze command</p> <p>Process single hyperspectral dataset</p> </li> <li> <p>batch command</p> <p>Process multiple datasets sequentially</p> </li> <li> <p>segment command</p> <p>Segmentation-only mode</p> </li> <li> <p>config command</p> <p>Generate configuration files</p> </li> </ul>"},{"location":"cli-reference/batch/","title":"batch","text":"<p>Process multiple hyperspectral datasets sequentially.</p>"},{"location":"cli-reference/batch/#synopsis","title":"Synopsis","text":"<pre><code>hyperseed batch INPUT_DIR [OPTIONS]\n</code></pre>"},{"location":"cli-reference/batch/#description","title":"Description","text":"<p>The <code>batch</code> command processes multiple datasets sequentially (one after another) with consistent settings. It applies the same analysis pipeline to each dataset and saves results to a structured output directory.</p>"},{"location":"cli-reference/batch/#arguments","title":"Arguments","text":""},{"location":"cli-reference/batch/#input_dir","title":"INPUT_DIR","text":"<p>Directory containing multiple dataset subdirectories.</p> <p>Required: Yes</p> <p>Format: Each subdirectory should contain: - <code>capture/data.raw</code> and <code>capture/data.hdr</code> (main data) - <code>capture/WHITEREF_data.raw</code> and <code>.hdr</code> (white reference) - <code>capture/DARKREF_data.raw</code> and <code>.hdr</code> (dark reference)</p> <p>Example: <pre><code>datasets/\n\u251c\u2500\u2500 sample_001/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u251c\u2500\u2500 data.raw, data.hdr\n\u2502       \u251c\u2500\u2500 WHITEREF_data.raw, WHITEREF_data.hdr\n\u2502       \u2514\u2500\u2500 DARKREF_data.raw, DARKREF_data.hdr\n\u251c\u2500\u2500 sample_002/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_003/\n    \u2514\u2500\u2500 capture/\n        \u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"cli-reference/batch/#options","title":"Options","text":""},{"location":"cli-reference/batch/#-o-output-dir-path","title":"-o, --output-dir PATH","text":"<p>Output directory for results.</p> <p>Type: Path Default: <code>INPUT_DIR/results</code></p> <p>All output files are saved to this directory with dataset names as prefixes.</p> <p>Example: <pre><code>hyperseed batch datasets/ --output-dir analysis_results/\n</code></pre></p>"},{"location":"cli-reference/batch/#-c-config-path","title":"-c, --config PATH","text":"<p>Path to YAML configuration file.</p> <p>Type: Path Default: None (uses default settings)</p> <p>Applies consistent preprocessing, segmentation, and output settings across all datasets.</p> <p>Example: <pre><code>hyperseed batch datasets/ --config batch_config.yaml\n</code></pre></p>"},{"location":"cli-reference/batch/#-pattern-text","title":"--pattern TEXT","text":"<p>Pattern to match dataset directories (glob-style).</p> <p>Type: Text Default: <code>*</code> (matches all subdirectories)</p> <p>Use glob patterns to filter which datasets to process.</p> <p>Example: <pre><code># Process only datasets starting with \"sample_\"\nhyperseed batch datasets/ --pattern \"sample_*\"\n\n# Process only SWIR datasets\nhyperseed batch datasets/ --pattern \"SWIR_*\"\n\n# Process specific range\nhyperseed batch datasets/ --pattern \"sample_00[1-5]\"\n</code></pre></p>"},{"location":"cli-reference/batch/#-min-pixels-integer","title":"--min-pixels INTEGER","text":"<p>Minimum seed size in pixels.</p> <p>Type: Integer Default: 200 Range: 10-10000</p> <p>Overrides the min_pixels setting from configuration.</p> <p>Example: <pre><code>hyperseed batch datasets/ --min-pixels 150\n</code></pre></p>"},{"location":"cli-reference/batch/#-no-outlier-removal","title":"--no-outlier-removal","text":"<p>Disable automatic outlier removal.</p> <p>Type: Flag (boolean) Default: False (outlier removal enabled)</p> <p>Disables outlier detection and removal for all datasets.</p> <p>Example: <pre><code>hyperseed batch datasets/ --no-outlier-removal\n</code></pre></p>"},{"location":"cli-reference/batch/#complete-examples","title":"Complete Examples","text":""},{"location":"cli-reference/batch/#basic-batch-processing","title":"Basic Batch Processing","text":"<pre><code>hyperseed batch datasets/\n</code></pre> <p>What it does: 1. Finds all subdirectories in <code>datasets/</code> 2. Processes each sequentially 3. Saves results to <code>datasets/results/</code></p>"},{"location":"cli-reference/batch/#custom-output-directory","title":"Custom Output Directory","text":"<pre><code>hyperseed batch datasets/ --output-dir analysis_results/\n</code></pre> <p>Output location: <code>analysis_results/</code></p>"},{"location":"cli-reference/batch/#filter-by-pattern","title":"Filter by Pattern","text":"<pre><code># Process only datasets starting with \"sample_\"\nhyperseed batch datasets/ --pattern \"sample_*\"\n\n# Process only specific samples\nhyperseed batch datasets/ --pattern \"sample_00[1-5]\"\n</code></pre>"},{"location":"cli-reference/batch/#with-configuration-file","title":"With Configuration File","text":"<pre><code>hyperseed batch datasets/ \\\n    --config batch_config.yaml \\\n    --output-dir results/\n</code></pre> <p>batch_config.yaml: <pre><code>preprocessing:\n  method: minimal  # Fast processing for batch\n\nsegmentation:\n  algorithm: watershed\n  min_pixels: 200\n  remove_outliers: true\n\noutput:\n  format: csv\n  include_plots: true\n</code></pre></p>"},{"location":"cli-reference/batch/#override-settings","title":"Override Settings","text":"<pre><code># Use config but override min_pixels\nhyperseed batch datasets/ \\\n    --config batch_config.yaml \\\n    --min-pixels 150 \\\n    --output-dir results/\n</code></pre>"},{"location":"cli-reference/batch/#output-structure","title":"Output Structure","text":"<p>For input directory <code>datasets/</code> containing <code>sample_001/</code>, <code>sample_002/</code>, etc., the batch command generates:</p> <pre><code>results/\n\u251c\u2500\u2500 sample_001_spectra.csv\n\u251c\u2500\u2500 sample_001_distribution.png\n\u251c\u2500\u2500 sample_001_segmentation.png\n\u251c\u2500\u2500 sample_001_spectra.png\n\u251c\u2500\u2500 sample_002_spectra.csv\n\u251c\u2500\u2500 sample_002_distribution.png\n\u251c\u2500\u2500 sample_002_segmentation.png\n\u251c\u2500\u2500 sample_002_spectra.png\n\u251c\u2500\u2500 sample_003_spectra.csv\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"cli-reference/batch/#generated-files-per-dataset","title":"Generated Files Per Dataset","text":"<p>For each dataset that contains seeds:</p> <ol> <li>{name}_spectra.csv - Extracted spectral data with metadata</li> <li>Seed IDs, coordinates, areas, morphology</li> <li> <p>Complete spectral signatures (all wavelengths)</p> </li> <li> <p>{name}_distribution.png - Spatial and size distribution</p> </li> <li>Left panel: Spatial distribution of seeds</li> <li> <p>Right panel: Area distribution histogram</p> </li> <li> <p>{name}_segmentation.png - Seed visualization</p> </li> <li>Left panel: Original image</li> <li>Middle panel: Numbered seeds with colors</li> <li> <p>Right panel: Seed boundaries overlay</p> </li> <li> <p>{name}_spectra.png - Spectral curves</p> </li> <li>Individual seed spectra (light lines)</li> <li>Mean spectrum (bold line)</li> <li>Standard deviation band (shaded)</li> </ol> <p>For datasets with no seeds: - No files are generated - Warning is displayed in console</p>"},{"location":"cli-reference/batch/#processing-pipeline","title":"Processing Pipeline","text":"<p>For each dataset, the batch command performs:</p> <ol> <li>Dataset Discovery</li> <li>Searches INPUT_DIR for subdirectories matching pattern</li> <li> <p>Filters to directories with <code>capture/</code> folder</p> </li> <li> <p>Sequential Processing (for each dataset)</p> </li> <li>Load and calibrate hyperspectral data</li> <li>Apply preprocessing (from config or defaults)</li> <li>Segment seeds</li> <li>Extract spectra</li> <li>Apply outlier removal (if enabled)</li> <li> <p>Save CSV and generate plots</p> </li> <li> <p>Error Handling</p> </li> <li>If a dataset fails, error is logged</li> <li>Processing continues with next dataset</li> <li> <p>Summary shows success/failure counts</p> </li> <li> <p>Summary Display</p> </li> <li>Total datasets processed</li> <li>Successful count</li> <li>Failed datasets (if any)</li> </ol>"},{"location":"cli-reference/batch/#dataset-discovery","title":"Dataset Discovery","text":"<p>The batch command automatically finds datasets with this structure:</p> <pre><code># Searches for directories matching pattern\nINPUT_DIR/{pattern}/capture/data.hdr\n\n# Examples found:\ndatasets/sample_001/capture/data.hdr  \u2713\ndatasets/sample_002/capture/data.hdr  \u2713\ndatasets/other_file.txt               \u2717 (not a directory)\ndatasets/no_capture/data.hdr          \u2717 (missing capture/ folder)\n</code></pre>"},{"location":"cli-reference/batch/#error-handling","title":"Error Handling","text":"<p>Batch processing continues even if individual datasets fail:</p> <pre><code>$ hyperseed batch datasets/ --output-dir results/\n\n[1/5] Processing sample_001...\n  \u2713 Processed: 47 seeds \u2192 sample_001_spectra.csv\n\n[2/5] Processing sample_002...\n  \u2717 Failed: ENVI header not found\n\n[3/5] Processing sample_003...\n  \u2713 Processed: 52 seeds \u2192 sample_003_spectra.csv\n\nBatch Processing Summary:\n  Successful: 3/5\n  Failed: sample_002, sample_004\n</code></pre> <p>Failed datasets: - Error message is displayed - Processing continues with next dataset - Failed datasets listed in summary</p> <p>Common failure reasons: - Missing data files - Corrupted ENVI headers - No seeds detected (if validation too strict) - Insufficient disk space</p>"},{"location":"cli-reference/batch/#performance-notes","title":"Performance Notes","text":""},{"location":"cli-reference/batch/#processing-time","title":"Processing Time","text":"<p>Batch processing is sequential (one dataset at a time):</p> <ul> <li>Time per dataset: ~30-60 seconds (typical)</li> <li>Total time: num_datasets \u00d7 time_per_dataset</li> </ul> <p>Example: <pre><code>10 datasets \u00d7 45 seconds = ~7.5 minutes total\n</code></pre></p>"},{"location":"cli-reference/batch/#reducing-processing-time","title":"Reducing Processing Time","text":"<pre><code># fast_config.yaml - Optimized for speed\npreprocessing:\n  method: minimal  # Minimal preprocessing (fastest)\n\nsegmentation:\n  algorithm: threshold  # Faster than watershed\n  min_pixels: 200\n  morphology_operations: false  # Skip cleanup\n  remove_outliers: false  # Skip outlier detection\n</code></pre> <pre><code>hyperseed batch datasets/ --config fast_config.yaml\n</code></pre>"},{"location":"cli-reference/batch/#memory-usage","title":"Memory Usage","text":"<ul> <li>Per dataset: ~1-2GB RAM</li> <li>Total: Same as single dataset (sequential processing)</li> </ul>"},{"location":"cli-reference/batch/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli-reference/batch/#issue-no-datasets-found","title":"Issue: No datasets found","text":"<p>Error: <code>No datasets found matching '*'</code></p> <p>Solutions: <pre><code># Check directory structure\nls -la datasets/\n\n# Verify capture folders exist\nfind datasets/ -name \"capture\" -type d\n\n# Check pattern\nhyperseed batch datasets/ --pattern \"*\" -v\n</code></pre></p>"},{"location":"cli-reference/batch/#issue-all-datasets-failing","title":"Issue: All datasets failing","text":"<p>Possible causes: - Incorrect directory structure - Missing reference files - Corrupted data</p> <p>Solutions: <pre><code># Test single dataset first\nhyperseed analyze datasets/sample_001 --output test.csv\n\n# Enable debug mode\nhyperseed batch datasets/ --debug\n</code></pre></p>"},{"location":"cli-reference/batch/#issue-some-seeds-missing","title":"Issue: Some seeds missing","text":"<p>Possible causes: - min_pixels threshold too high - Outlier removal too aggressive</p> <p>Solutions: <pre><code># Lower min_pixels\nhyperseed batch datasets/ --min-pixels 100\n\n# Disable outlier removal\nhyperseed batch datasets/ --no-outlier-removal\n\n# Use custom config with looser thresholds\n</code></pre></p>"},{"location":"cli-reference/batch/#issue-processing-too-slow","title":"Issue: Processing too slow","text":"<p>Solutions: <pre><code># Use minimal preprocessing\nhyperseed batch datasets/ --config fast_config.yaml\n\n# Reduce plot generation (custom config)\n</code></pre></p> <pre><code># fast_config.yaml\noutput:\n  include_plots: false  # Skip plots for speed\n</code></pre>"},{"location":"cli-reference/batch/#comparison-with-analyze-command","title":"Comparison with analyze Command","text":"Feature batch analyze Datasets Multiple Single Processing Sequential Single run Output Multiple files Single file set Error handling Continues on failure Stops on error Progress Shows count (1/N) Shows progress bar Interactive No Optional (--export-plots) Use case Process many datasets Detailed single analysis <p>When to use batch: - Processing multiple datasets with same settings - Automated workflows - Consistent analysis across samples</p> <p>When to use analyze: - Single dataset analysis - Testing different parameters - Need detailed progress information</p>"},{"location":"cli-reference/batch/#advanced-usage","title":"Advanced Usage","text":""},{"location":"cli-reference/batch/#batch-with-different-settings-per-type","title":"Batch with Different Settings Per Type","text":"<p>Process different dataset types with different configs:</p> <pre><code># Process SWIR datasets with one config\nhyperseed batch datasets/ \\\n    --pattern \"SWIR_*\" \\\n    --config swir_config.yaml \\\n    --output-dir results_swir/\n\n# Process VIS datasets with another config\nhyperseed batch datasets/ \\\n    --pattern \"VIS_*\" \\\n    --config vis_config.yaml \\\n    --output-dir results_vis/\n</code></pre>"},{"location":"cli-reference/batch/#progress-monitoring","title":"Progress Monitoring","text":"<pre><code># Run with verbose output\nhyperseed batch datasets/ -v --output-dir results/\n\n# Monitor output directory\nwatch -n 5 'ls -lh results/*.csv | wc -l'\n</code></pre>"},{"location":"cli-reference/batch/#resume-failed-processing","title":"Resume Failed Processing","text":"<pre><code># First run - some fail\nhyperseed batch datasets/ --output-dir results/\n\n# Find what succeeded\nls results/*.csv\n\n# Process only missing datasets\nhyperseed batch datasets/ \\\n    --pattern \"sample_00[6-9]\" \\\n    --output-dir results/\n</code></pre>"},{"location":"cli-reference/batch/#see-also","title":"See Also","text":"<ul> <li>analyze command: Process single dataset</li> <li>Configuration Guide: Create batch configurations</li> <li>Batch Processing Guide: Detailed workflows and examples</li> </ul>"},{"location":"cli-reference/calibrate/","title":"Calibration (via analyze command)","text":"<p>No Standalone Calibrate Command</p> <p>Hyperseed does not have a standalone <code>calibrate</code> command. Calibration is performed automatically as part of the <code>analyze</code> workflow.</p>"},{"location":"cli-reference/calibrate/#how-calibration-works","title":"How Calibration Works","text":"<p>Calibration is automatically performed when you run the <code>analyze</code> command:</p> <pre><code>hyperseed analyze dataset/sample_001 --output results.csv\n</code></pre> <p>The calibration process:</p> <ol> <li>Automatically finds white and dark reference files in the dataset</li> <li>Applies reflectance calibration with bad pixel interpolation</li> <li>Clips negative values and maximum reflectance (configurable)</li> <li>Passes calibrated data to preprocessing and segmentation</li> </ol>"},{"location":"cli-reference/calibrate/#calibration-via-python-api","title":"Calibration via Python API","text":"<p>For programmatic control over calibration, use the Python API:</p> <pre><code>from hyperseed.core.calibration.reflectance import ReflectanceCalibrator\n\n# Create calibrator with custom settings\ncalibrator = ReflectanceCalibrator(\n    clip_negative=True,\n    clip_max=1.0\n)\n\n# Calibrate from directory (auto-finds references)\ncalibrated_data, reader = calibrator.calibrate_from_directory(\n    \"path/to/dataset\"\n)\n\n# Or calibrate with explicit references\ncalibrated = calibrator.calibrate(\n    raw_data=raw_data,\n    white_ref=white_reference,\n    dark_ref=dark_reference\n)\n</code></pre>"},{"location":"cli-reference/calibrate/#configuration-options","title":"Configuration Options","text":"<p>Configure calibration in your YAML config file:</p> <pre><code>calibration:\n  apply_calibration: true\n  clip_negative: true\n  clip_max: 1.0\n  apply_bad_pixels: true\n</code></pre> <p>Then use with analyze:</p> <pre><code>hyperseed analyze dataset/sample_001 --config config.yaml\n</code></pre>"},{"location":"cli-reference/calibrate/#see-also","title":"See Also","text":"<ul> <li>analyze command: Full analysis pipeline including calibration</li> <li>Configuration Guide: Calibration configuration options</li> <li>API Reference: ReflectanceCalibrator class documentation</li> </ul>"},{"location":"cli-reference/extract/","title":"analyze","text":"<p>The main command for processing hyperspectral seed imagery.</p>"},{"location":"cli-reference/extract/#synopsis","title":"Synopsis","text":"<pre><code>hyperseed analyze INPUT_PATH [OPTIONS]\n</code></pre>"},{"location":"cli-reference/extract/#description","title":"Description","text":"<p>The <code>analyze</code> command performs complete hyperspectral seed analysis:</p> <ol> <li>Loads ENVI format hyperspectral data</li> <li>Applies reflectance calibration with white/dark references</li> <li>Performs spectral preprocessing</li> <li>Segments individual seeds</li> <li>Extracts spectral signatures</li> <li>Exports results to CSV or HDF5</li> </ol>"},{"location":"cli-reference/extract/#arguments","title":"Arguments","text":"<code>INPUT_PATH</code> (required) Path to the hyperspectral dataset directory"},{"location":"cli-reference/extract/#options","title":"Options","text":""},{"location":"cli-reference/extract/#output-options","title":"Output Options","text":"<code>-o, --output PATH</code> (required) Output file path (<code>.csv</code> or <code>.h5</code>) <code>--export-plots</code> Generate visualization plots (distribution, segmentation, spectra) <code>--export-mask</code> Export segmentation mask as <code>.npy</code> file"},{"location":"cli-reference/extract/#processing-options","title":"Processing Options","text":"<code>-c, --config PATH</code> Path to YAML configuration file <code>--preprocess CHOICE</code> Preprocessing preset: <code>minimal</code>, <code>standard</code>, <code>advanced</code>, <code>none</code> Default: <code>standard</code> <code>--segmentation CHOICE</code> Segmentation algorithm: <code>threshold</code>, <code>watershed</code>, <code>connected</code>, <code>combined</code> Default: <code>watershed</code> <code>--min-pixels INT</code> Minimum seed size in pixels Default: <code>200</code> <code>--no-outlier-removal</code> Disable automatic outlier detection and removal"},{"location":"cli-reference/extract/#logging-options","title":"Logging Options","text":"<code>-v, --verbose</code> Enable verbose logging <code>-d, --debug</code> Enable debug mode with detailed logging"},{"location":"cli-reference/extract/#examples","title":"Examples","text":""},{"location":"cli-reference/extract/#basic-analysis","title":"Basic Analysis","text":"<pre><code>hyperseed analyze dataset/sample_001 --output results.csv\n</code></pre>"},{"location":"cli-reference/extract/#with-visualizations","title":"With Visualizations","text":"<pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --export-plots\n</code></pre>"},{"location":"cli-reference/extract/#recommended-settings-for-seeds","title":"Recommended Settings for Seeds","text":"<pre><code>hyperseed analyze dataset/sample_data \\\n    --output seed_analysis.csv \\\n    --min-pixels 50 \\\n    --preprocess minimal \\\n    --export-plots\n</code></pre>"},{"location":"cli-reference/extract/#using-custom-configuration","title":"Using Custom Configuration","text":"<pre><code>hyperseed analyze dataset/sample \\\n    --output results.csv \\\n    --config custom_settings.yaml\n</code></pre>"},{"location":"cli-reference/extract/#disable-outlier-removal","title":"Disable Outlier Removal","text":"<pre><code>hyperseed analyze dataset/sample_data \\\n    --output results.csv \\\n    --min-pixels 50 \\\n    --no-outlier-removal\n</code></pre>"},{"location":"cli-reference/extract/#output-files","title":"Output Files","text":"<p>For input <code>dataset/sample</code> with output <code>results.csv</code> and <code>--export-plots</code>:</p> <ol> <li>results.csv - Extracted seed spectra with metadata</li> <li>results_distribution.png - Spatial and size distribution</li> <li>results_segmentation.png - Numbered seed visualization</li> <li>results_spectra.png - Individual and mean spectra</li> <li>results_spectra_statistics.png - Statistical analysis</li> <li>results_mask.npy - Segmentation mask (if <code>--export-mask</code>)</li> </ol>"},{"location":"cli-reference/extract/#csv-output-format","title":"CSV Output Format","text":"<pre><code>seed_id,index,centroid_y,centroid_x,area,eccentricity,solidity,band_1000nm,band_1005nm,...\n1,0,234.5,156.2,435,0.34,0.92,0.234,0.237,...\n2,1,345.6,234.1,421,0.28,0.94,0.229,0.232,...\n</code></pre> <p>Columns: - seed_id: Sequential seed identifier - index: Original label from segmentation - centroid_y, centroid_x: Seed center coordinates - area: Seed area in pixels - eccentricity: Shape eccentricity (0=circle, 1=line) - solidity: Shape solidity (convex hull ratio) - band_*: Reflectance values at each wavelength</p>"},{"location":"cli-reference/extract/#see-also","title":"See Also","text":"<ul> <li>batch: Process multiple datasets</li> <li>Configuration Guide: Detailed configuration options</li> <li>Quick Start: Tutorial walkthrough</li> </ul>"},{"location":"cli-reference/segment/","title":"segment","text":"<p>Perform seed segmentation only, without spectral extraction.</p> <p>The <code>segment</code> command is useful for:</p> <ul> <li>Testing segmentation parameters before full analysis</li> <li>Visualizing segmentation results interactively</li> <li>Exporting segmentation masks for external processing</li> <li>Quick quality checks on imaging setup</li> </ul>"},{"location":"cli-reference/segment/#syntax","title":"Syntax","text":"<pre><code>hyperseed segment INPUT_PATH [OPTIONS]\n</code></pre>"},{"location":"cli-reference/segment/#arguments","title":"Arguments","text":""},{"location":"cli-reference/segment/#input_path","title":"INPUT_PATH","text":"<p>Path to the hyperspectral dataset directory.</p> <p>Required: Yes</p> <p>Format: Directory containing: - <code>capture/data.raw</code> and <code>capture/data.hdr</code> (main data) - <code>capture/WHITEREF_data.raw</code> and <code>.hdr</code> (white reference) - <code>capture/DARKREF_data.raw</code> and <code>.hdr</code> (dark reference)</p> <p>Example: <pre><code>hyperseed segment dataset/sample_001\n</code></pre></p>"},{"location":"cli-reference/segment/#options","title":"Options","text":""},{"location":"cli-reference/segment/#-o-output-path","title":"-o, --output PATH","text":"<p>Output file path for segmentation mask.</p> <p>Type: Path Default: None (no mask saved) Format: <code>.npy</code> (NumPy array format)</p> <p>Example: <pre><code>hyperseed segment dataset/sample \\\n    --output segmentation_mask.npy\n</code></pre></p> <p>Note: The mask is a 2D labeled array where each seed has a unique integer ID (0 = background).</p>"},{"location":"cli-reference/segment/#-algorithm-choice","title":"--algorithm CHOICE","text":"<p>Segmentation algorithm to use.</p> <p>Type: Choice Choices: <code>threshold</code>, <code>watershed</code>, <code>connected</code>, <code>combined</code> Default: <code>watershed</code></p> <p>Example: <pre><code># Fast thresholding\nhyperseed segment dataset/sample --algorithm threshold\n\n# Watershed (default, recommended)\nhyperseed segment dataset/sample --algorithm watershed\n\n# Connected components\nhyperseed segment dataset/sample --algorithm connected\n\n# Combined (most robust)\nhyperseed segment dataset/sample --algorithm combined\n</code></pre></p> <p>Algorithm descriptions:</p> Algorithm Speed Separates touching seeds Best for <code>threshold</code> \u26a1\u26a1\u26a1 \u274c Well-separated seeds, quick tests <code>watershed</code> \u26a1\u26a1 \u2705 General use (recommended) <code>connected</code> \u26a1\u26a1\u26a1 \u274c Simple, well-separated seeds <code>combined</code> \u26a1 \u2705 Maximum accuracy, robust"},{"location":"cli-reference/segment/#-min-pixels-integer","title":"--min-pixels INTEGER","text":"<p>Minimum seed size in pixels.</p> <p>Type: Integer Default: 200 Range: 10-10000</p> <p>Seeds smaller than this threshold are filtered out as noise or debris.</p> <p>Example: <pre><code># Small seeds or high resolution\nhyperseed segment dataset/sample --min-pixels 100\n\n# Default\nhyperseed segment dataset/sample --min-pixels 200\n\n# Large seeds or low resolution\nhyperseed segment dataset/sample --min-pixels 300\n</code></pre></p> <p>Guidelines: - Small seeds (&lt; 5mm) or high-resolution images: 100-150 - Medium seeds (default): 200 - Large seeds (&gt; 10mm) or low-resolution: 300-500</p>"},{"location":"cli-reference/segment/#-visualize","title":"--visualize","text":"<p>Show segmentation visualization.</p> <p>Type: Flag (boolean) Default: False</p> <p>Displays an interactive visualization showing: - Original image - Segmentation with numbered seeds - Seed boundaries overlay</p> <p>Example: <pre><code>hyperseed segment dataset/sample --visualize\n</code></pre></p> <p>Note: Requires display (won't work in headless environments). Press any key to close the visualization window.</p>"},{"location":"cli-reference/segment/#-help","title":"--help","text":"<p>Show help message and exit.</p> <p>Example: <pre><code>hyperseed segment --help\n</code></pre></p>"},{"location":"cli-reference/segment/#complete-examples","title":"Complete Examples","text":""},{"location":"cli-reference/segment/#basic-segmentation-with-visualization","title":"Basic Segmentation with Visualization","text":"<pre><code>hyperseed segment dataset/sample_001 --visualize\n</code></pre> <p>What it does: 1. Loads and calibrates hyperspectral data 2. Applies minimal preprocessing (smoothing only) 3. Segments seeds using watershed algorithm 4. Displays interactive visualization</p>"},{"location":"cli-reference/segment/#save-segmentation-mask","title":"Save Segmentation Mask","text":"<pre><code>hyperseed segment dataset/sample_001 \\\n    --output results/sample_001_mask.npy \\\n    --algorithm watershed \\\n    --min-pixels 200\n</code></pre> <p>Output: <code>results/sample_001_mask.npy</code> - NumPy array with labeled seeds</p> <p>Load mask in Python: <pre><code>import numpy as np\nmask = np.load('results/sample_001_mask.npy')\nprint(f\"Found {mask.max()} seeds\")\n</code></pre></p>"},{"location":"cli-reference/segment/#test-different-algorithms","title":"Test Different Algorithms","text":"<pre><code># Test threshold\nhyperseed segment dataset/sample --algorithm threshold --visualize\n\n# Test watershed\nhyperseed segment dataset/sample --algorithm watershed --visualize\n\n# Test combined\nhyperseed segment dataset/sample --algorithm combined --visualize\n</code></pre> <p>Use case: Compare algorithms visually to choose the best for your data.</p>"},{"location":"cli-reference/segment/#adjust-size-threshold","title":"Adjust Size Threshold","text":"<pre><code># Lower threshold for small seeds\nhyperseed segment dataset/sample --min-pixels 100 --visualize\n\n# Higher threshold to remove noise\nhyperseed segment dataset/sample --min-pixels 300 --visualize\n</code></pre>"},{"location":"cli-reference/segment/#processing-pipeline","title":"Processing Pipeline","text":"<p>The <code>segment</code> command performs these steps:</p> <ol> <li>Load data from ENVI format files</li> <li>Calibrate using white/dark references</li> <li>Preprocess with minimal preset (smoothing only)</li> <li>Segment using selected algorithm</li> <li>Filter by size (<code>min_pixels</code>)</li> <li>Visualize (if <code>--visualize</code> flag set)</li> <li>Export mask (if <code>--output</code> specified)</li> </ol> <p>Note: The segment command does NOT perform: - Outlier removal (use <code>analyze</code> command for this) - Spectral extraction (use <code>analyze</code> command) - Advanced preprocessing (always uses minimal)</p>"},{"location":"cli-reference/segment/#output-format","title":"Output Format","text":""},{"location":"cli-reference/segment/#segmentation-mask-npy","title":"Segmentation Mask (.npy)","text":"<p>A 2D NumPy array with the same spatial dimensions as the input image.</p> <p>Format: - dtype: <code>int32</code> or <code>int64</code> - Values:   - <code>0</code> = background (no seed)   - <code>1, 2, 3, ...</code> = seed IDs</p> <p>Example structure: <pre><code>import numpy as np\nmask = np.load('mask.npy')\n\n# mask.shape: (lines, samples)\n# Example: (384, 512)\n\n# Get seed IDs\nseed_ids = np.unique(mask[mask &gt; 0])\nprint(f\"Seeds detected: {seed_ids}\")\n# Output: Seeds detected: [1 2 3 4 5 ... 47]\n\n# Get pixels for seed #5\nseed_5_pixels = mask == 5\nseed_5_area = np.sum(seed_5_pixels)\nprint(f\"Seed 5 area: {seed_5_area} pixels\")\n</code></pre></p>"},{"location":"cli-reference/segment/#comparison-with-analyze-command","title":"Comparison with analyze Command","text":"Feature segment analyze Segmentation \u2705 Yes \u2705 Yes Spectral extraction \u274c No \u2705 Yes Outlier removal \u274c No \u2705 Yes (default) Preprocessing Minimal only All presets Visualization Interactive Exported plots Output Mask only CSV + plots + mask Speed Faster Slower Use case Testing, quick checks Full analysis <p>When to use segment: - Testing segmentation parameters - Visualizing results quickly - You only need the mask - Performing custom spectral analysis later</p> <p>When to use analyze: - Complete analysis workflow - Need spectral data extracted - Want outlier removal - Need CSV output with spectra</p>"},{"location":"cli-reference/segment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli-reference/segment/#issue-no-display-available","title":"Issue: No display available","text":"<p>Error: <code>Cannot connect to display</code></p> <p>Solution: Run without <code>--visualize</code> in headless environments: <pre><code>hyperseed segment dataset/sample --output mask.npy\n</code></pre></p>"},{"location":"cli-reference/segment/#issue-too-manytoo-few-seeds-detected","title":"Issue: Too many/too few seeds detected","text":"<p>Solution: Adjust <code>min_pixels</code>: <pre><code># Increase to reduce detections\nhyperseed segment dataset/sample --min-pixels 300 --visualize\n\n# Decrease to increase detections\nhyperseed segment dataset/sample --min-pixels 150 --visualize\n</code></pre></p>"},{"location":"cli-reference/segment/#issue-touching-seeds-not-separated","title":"Issue: Touching seeds not separated","text":"<p>Solution: Use watershed or combined algorithm: <pre><code>hyperseed segment dataset/sample \\\n    --algorithm watershed \\\n    --visualize\n</code></pre></p>"},{"location":"cli-reference/segment/#issue-segmentation-quality-poor","title":"Issue: Segmentation quality poor","text":"<p>Possible causes: - Algorithm not suitable for seed arrangement - Preprocessing too aggressive (segment always uses minimal) - Poor image quality/contrast</p> <p>Solutions: <pre><code># Try different algorithm\nhyperseed segment dataset/sample --algorithm combined --visualize\n\n# For full control, use analyze command with custom config\nhyperseed analyze dataset/sample --config custom_config.yaml\n</code></pre></p>"},{"location":"cli-reference/segment/#advanced-usage","title":"Advanced Usage","text":""},{"location":"cli-reference/segment/#batch-testing-algorithms","title":"Batch Testing Algorithms","text":"<p>Test all algorithms on the same dataset:</p> <pre><code>#!/bin/bash\nfor algo in threshold watershed connected combined; do\n    echo \"Testing $algo...\"\n    hyperseed segment dataset/sample \\\n        --algorithm $algo \\\n        --output masks/${algo}_mask.npy\ndone\n</code></pre>"},{"location":"cli-reference/segment/#compare-segmentation-with-different-min_pixels","title":"Compare Segmentation with Different min_pixels","text":"<pre><code>#!/bin/bash\nfor pixels in 100 150 200 250 300; do\n    echo \"Testing min_pixels=$pixels...\"\n    hyperseed segment dataset/sample \\\n        --min-pixels $pixels \\\n        --output masks/mask_${pixels}px.npy\ndone\n</code></pre>"},{"location":"cli-reference/segment/#extract-statistics-from-mask","title":"Extract Statistics from Mask","text":"<pre><code>import numpy as np\nfrom skimage import measure\n\n# Load mask\nmask = np.load('segmentation_mask.npy')\n\n# Get region properties\nprops = measure.regionprops(mask)\n\n# Print statistics\nprint(f\"Total seeds: {len(props)}\")\nprint(f\"Mean area: {np.mean([p.area for p in props]):.1f} pixels\")\nprint(f\"Area range: {min(p.area for p in props)}-{max(p.area for p in props)} pixels\")\n\n# Export to CSV\nimport pandas as pd\ndata = [{\n    'seed_id': p.label,\n    'area': p.area,\n    'centroid_y': p.centroid[0],\n    'centroid_x': p.centroid[1],\n    'eccentricity': p.eccentricity,\n    'solidity': p.solidity\n} for p in props]\ndf = pd.DataFrame(data)\ndf.to_csv('seed_properties.csv', index=False)\n</code></pre>"},{"location":"cli-reference/segment/#see-also","title":"See Also","text":"<ul> <li>analyze command: Complete analysis with spectral extraction</li> <li>Segmentation Guide: Detailed algorithm descriptions</li> <li>Configuration: All segmentation parameters</li> <li>API Reference: Programmatic segmentation</li> </ul>"},{"location":"development/","title":"Development","text":"<p>Information for developers and contributors.</p>"},{"location":"development/#overview","title":"Overview","text":"<p>Hyperseed is an open-source project and welcomes contributions! This section provides resources for developers who want to:</p> <ul> <li>Contribute code, documentation, or bug fixes</li> <li>Understand the project architecture</li> <li>Run tests and ensure code quality</li> <li>Build and deploy the project</li> </ul>"},{"location":"development/#for-contributors","title":"For Contributors","text":"<ul> <li> <p>Contributing Guide</p> <p>How to contribute to Hyperseed</p> </li> <li> <p>Architecture</p> <p>Project structure and design</p> </li> <li> <p>Testing</p> <p>Running tests and ensuring quality</p> </li> </ul>"},{"location":"development/#quick-start-for-developers","title":"Quick Start for Developers","text":""},{"location":"development/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork on GitHub, then clone your fork\ngit clone https://github.com/YOUR_USERNAME/hyperseed\ncd hyperseed\n</code></pre>"},{"location":"development/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"<pre><code># Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\n# Install in development mode\npip install -e \".[dev]\"\n</code></pre>"},{"location":"development/#3-make-changes","title":"3. Make Changes","text":"<pre><code># Create a new branch\ngit checkout -b feature/my-new-feature\n\n# Make your changes\n# ...\n\n# Format code\nblack hyperseed/\nruff check hyperseed/\n\n# Run tests\npytest\n</code></pre>"},{"location":"development/#4-submit-pull-request","title":"4. Submit Pull Request","text":"<pre><code># Commit and push\ngit add .\ngit commit -m \"Add my new feature\"\ngit push origin feature/my-new-feature\n\n# Create pull request on GitHub\n</code></pre>"},{"location":"development/#development-tools","title":"Development Tools","text":"<p>Hyperseed uses modern Python development tools:</p> Tool Purpose pytest Testing framework black Code formatting ruff Fast linting mypy Type checking mkdocs-material Documentation"},{"location":"development/#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>Test coverage: Aim for &gt;80% coverage</li> <li>Code style: Follow PEP 8 (enforced by black)</li> <li>Type hints: Add type hints to public functions</li> <li>Documentation: Document all public APIs</li> </ul>"},{"location":"development/#resources","title":"Resources","text":"<ul> <li>GitHub Repository: nishad/hyperseed</li> <li>Issue Tracker: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul>"},{"location":"development/architecture/","title":"Architecture","text":"<p>Project structure and design overview.</p>"},{"location":"development/architecture/#project-structure","title":"Project Structure","text":"<pre><code>hyperseed/\n\u251c\u2500\u2500 hyperseed/\n\u2502   \u251c\u2500\u2500 cli/                 # Command-line interface\n\u2502   \u251c\u2500\u2500 config/              # Configuration management\n\u2502   \u251c\u2500\u2500 core/                # Core functionality\n\u2502   \u2502   \u251c\u2500\u2500 io/              # ENVI file reading\n\u2502   \u2502   \u251c\u2500\u2500 calibration/     # Reflectance calibration\n\u2502   \u2502   \u251c\u2500\u2500 preprocessing/   # Spectral preprocessing\n\u2502   \u2502   \u251c\u2500\u2500 segmentation/    # Seed detection\n\u2502   \u2502   \u2514\u2500\u2500 extraction/      # Spectral extraction\n\u2502   \u2514\u2500\u2500 tests/               # Test suite\n\u251c\u2500\u2500 docs/                    # Documentation\n\u251c\u2500\u2500 pyproject.toml          # Project configuration\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"development/architecture/#design-principles","title":"Design Principles","text":"<ul> <li>Modular: Each component is independent</li> <li>Extensible: Easy to add new algorithms</li> <li>Testable: Comprehensive test coverage</li> <li>Documented: Clear documentation for all APIs</li> </ul>"},{"location":"development/architecture/#core-components","title":"Core Components","text":""},{"location":"development/architecture/#io-module","title":"I/O Module","text":"<p>Handles reading ENVI format hyperspectral data.</p>"},{"location":"development/architecture/#calibration-module","title":"Calibration Module","text":"<p>Applies white/dark reference correction.</p>"},{"location":"development/architecture/#preprocessing-module","title":"Preprocessing Module","text":"<p>Spectral preprocessing transformations.</p>"},{"location":"development/architecture/#segmentation-module","title":"Segmentation Module","text":"<p>Seed detection and isolation.</p>"},{"location":"development/architecture/#extraction-module","title":"Extraction Module","text":"<p>Spectral signature extraction.</p>"},{"location":"development/contributing/","title":"Contributing to Hyperseed","text":"<p>Thank you for considering contributing to Hyperseed! This document provides guidelines for contributing.</p>"},{"location":"development/contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Report bugs: Open an issue on GitHub</li> <li>Suggest features: Propose new features via issues</li> <li>Improve documentation: Fix typos, add examples, clarify</li> <li>Submit code: Fix bugs or implement features</li> </ul>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally</li> <li>Create a new branch for your changes</li> <li>Make your changes</li> <li>Run tests and ensure they pass</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone your fork\ngit clone https://github.com/YOUR_USERNAME/hyperseed\ncd hyperseed\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# Install in development mode\npip install -e \".[dev]\"\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<p>We use black for code formatting:</p> <pre><code>black hyperseed/\n</code></pre> <p>Lint with ruff:</p> <pre><code>ruff check hyperseed/\n</code></pre> <p>Type check with mypy:</p> <pre><code>mypy hyperseed/\n</code></pre>"},{"location":"development/contributing/#testing","title":"Testing","text":"<p>Run all tests:</p> <pre><code>pytest\n</code></pre> <p>Run with coverage:</p> <pre><code>pytest --cov=hyperseed --cov-report=html\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation if needed</li> <li>Add tests for new functionality</li> <li>Ensure all tests pass</li> <li>Update CHANGELOG.md</li> <li>Submit pull request with clear description</li> </ol>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Be respectful and constructive in all interactions.</p>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>All contributors are automatically recognized on the GitHub Contributors page. Your contributions, whether code, documentation, bug reports, or feature suggestions, are valued and appreciated!</p>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Open a GitHub issue or discussion if you have questions.</p>"},{"location":"development/testing/","title":"Testing","text":"<p>Guide to running tests and ensuring code quality.</p>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#all-tests","title":"All Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"development/testing/#with-coverage","title":"With Coverage","text":"<pre><code>pytest --cov=hyperseed --cov-report=html\n</code></pre> <p>View coverage report: <pre><code>open htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre></p>"},{"location":"development/testing/#specific-module","title":"Specific Module","text":"<pre><code>pytest tests/test_preprocessing.py -v\n</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 fixtures/          # Test data and fixtures\n\u251c\u2500\u2500 test_calibration.py\n\u251c\u2500\u2500 test_preprocessing.py\n\u251c\u2500\u2500 test_segmentation.py\n\u2514\u2500\u2500 test_extraction.py\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":"<p>Use pytest fixtures for setup:</p> <pre><code>import pytest\n\n@pytest.fixture\ndef sample_data():\n    return np.random.rand(100, 100, 224)\n\ndef test_preprocessing(sample_data):\n    from hyperseed.core.preprocessing import PreprocessingPipeline\n    pipeline = PreprocessingPipeline()\n    result = pipeline.fit_transform(sample_data)\n    assert result.shape == sample_data.shape\n</code></pre>"},{"location":"development/testing/#code-quality","title":"Code Quality","text":"<p>Ensure code quality before submitting:</p> <pre><code># Format\nblack hyperseed/\n\n# Lint\nruff check hyperseed/\n\n# Type check\nmypy hyperseed/\n\n# Test\npytest --cov=hyperseed\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to Hyperseed! This section will help you get up and running with hyperspectral seed analysis.</p>"},{"location":"getting-started/#overview","title":"Overview","text":"<p>Hyperseed provides a complete pipeline for analyzing hyperspectral imagery of plant seeds:</p> <ol> <li>Install the package via pip or from source</li> <li>Prepare your ENVI format hyperspectral data</li> <li>Configure analysis parameters (or use defaults)</li> <li>Analyze single datasets or batch process multiple datasets</li> <li>Visualize results with auto-generated plots</li> </ol>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li> <p> Installation</p> <p>Install Hyperseed using pip, from GitHub, or from source</p> </li> <li> <p> Quick Start</p> <p>Run your first analysis in 5 minutes</p> </li> <li> <p> Configuration</p> <p>Customize the analysis pipeline for your needs</p> </li> </ul>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Python 3.10+ installed on your system</li> <li>8GB+ RAM available (recommended)</li> <li>Hyperspectral data in ENVI format with white/dark references</li> </ul>"},{"location":"getting-started/#typical-workflow","title":"Typical Workflow","text":"<pre><code>graph LR\n    A[Install Hyperseed] --&gt; B[Prepare Data]\n    B --&gt; C[Run Analysis]\n    C --&gt; D[Review Results]\n    D --&gt; E{Satisfied?}\n    E --&gt;|No| F[Adjust Config]\n    F --&gt; C\n    E --&gt;|Yes| G[Export &amp; Publish]</code></pre>"},{"location":"getting-started/#need-help","title":"Need Help?","text":"<ul> <li>Issues: Report bugs on GitHub Issues</li> <li>Questions: Check the Troubleshooting Guide</li> <li>Examples: See User Guide for detailed examples</li> </ul> <p>Ready to begin? Start with Installation \u2192</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to customize Hyperseed's analysis pipeline using configuration files.</p>"},{"location":"getting-started/configuration/#overview","title":"Overview","text":"<p>Hyperseed can be configured in three ways:</p> <ol> <li>Command-line arguments (quick, one-off adjustments)</li> <li>YAML configuration files (reproducible, shareable settings)</li> <li>Python API (programmatic control)</li> </ol> <p>This guide focuses on YAML configuration files, which provide the most flexibility and reproducibility.</p>"},{"location":"getting-started/configuration/#generating-a-configuration-file","title":"Generating a Configuration File","text":"<p>Generate a configuration template:</p> <pre><code>hyperseed config --output my_config.yaml --preset minimal\n</code></pre> <p>Available presets:</p> Preset Description Use Case <code>minimal</code> Minimal preprocessing Best for segmentation (recommended) <code>standard</code> Moderate preprocessing Balanced for most applications <code>advanced</code> Full preprocessing pipeline Maximum spectral transformation <code>none</code> No preprocessing Raw data analysis"},{"location":"getting-started/configuration/#configuration-structure","title":"Configuration Structure","text":"<p>A complete configuration file has four main sections:</p> <pre><code>calibration:    # White/dark reference correction\npreprocessing:  # Spectral preprocessing\nsegmentation:   # Seed detection and isolation\noutput:         # Results and visualization\n</code></pre>"},{"location":"getting-started/configuration/#calibration-settings","title":"Calibration Settings","text":"<p>Configure white and dark reference calibration:</p> <pre><code>calibration:\n  apply_calibration: true    # Enable/disable calibration\n  clip_negative: true        # Clip negative reflectance values to 0\n  clip_max: 1.0             # Clip maximum reflectance to 1.0\n  interpolate_bad_pixels: true  # Automatically fix bad pixels\n</code></pre>"},{"location":"getting-started/configuration/#parameters-explained","title":"Parameters Explained","text":"<code>apply_calibration</code> (boolean, default: true) Enable or disable reflectance calibration using white/dark references. <code>clip_negative</code> (boolean, default: true) Clip negative reflectance values to zero (physically meaningful). <code>clip_max</code> (float, default: 1.0) Maximum reflectance value to clip at (1.0 = 100% reflectance). <code>interpolate_bad_pixels</code> (boolean, default: true) Automatically detect and interpolate bad pixels in references. <p>Recommended Settings</p> <p>Keep <code>apply_calibration: true</code> and <code>interpolate_bad_pixels: true</code> for best results.</p>"},{"location":"getting-started/configuration/#preprocessing-settings","title":"Preprocessing Settings","text":"<p>Configure spectral preprocessing methods:</p> <pre><code>preprocessing:\n  method: minimal              # Preset: minimal, standard, advanced, none\n\n  # Individual preprocessing options\n  snv: false                   # Standard Normal Variate\n  smoothing: true              # Savitzky-Golay smoothing\n  smoothing_window: 11         # Smoothing window size (must be odd, range: 3-51)\n  smoothing_polyorder: 3       # Polynomial order for smoothing (range: 1-5)\n  baseline_correction: false   # Baseline correction\n  baseline_order: 2            # Polynomial order for baseline (range: 1-5)\n  derivative: 0                # Derivative order (0, 1, or 2)\n  msc: false                   # Multiplicative Scatter Correction\n  detrend: false               # Remove linear trends\n</code></pre>"},{"location":"getting-started/configuration/#preprocessing-methods","title":"Preprocessing Methods","text":"<p>The <code>method</code> parameter provides preset combinations:</p> minimal (Recommended)standardadvancednone <pre><code>preprocessing:\n  method: minimal\n  # Enables: smoothing only\n  # Best for: Segmentation quality\n</code></pre> <pre><code>preprocessing:\n  method: standard\n  # Enables: SNV, smoothing, baseline correction\n  # Best for: Balanced preprocessing\n</code></pre> <pre><code>preprocessing:\n  method: advanced\n  # Enables: SNV, smoothing, baseline correction, 2nd derivative, MSC, detrend\n  # Best for: Chemometrics and advanced spectral analysis\n</code></pre> <pre><code>preprocessing:\n  method: none\n  # Enables: nothing\n  # Best for: Raw data analysis\n</code></pre>"},{"location":"getting-started/configuration/#individual-parameters","title":"Individual Parameters","text":"<code>snv</code> (boolean, default: false) Standard Normal Variate - removes multiplicative scatter effects. <code>smoothing</code> (boolean, default: true) Savitzky-Golay smoothing to reduce noise. <code>smoothing_window</code> (int, default: 11) Window size for smoothing (must be odd number, range: 3-51). <code>smoothing_polyorder</code> (int, default: 3) Polynomial order for Savitzky-Golay filter (range: 1-5). <code>baseline_correction</code> (boolean, default: false) Remove baseline drift in spectra using polynomial fitting. <code>baseline_order</code> (int, default: 2) Polynomial order for baseline correction (range: 1-5). <code>derivative</code> (int, default: 0) Derivative order: 0 (none), 1 (first), 2 (second). Computed using Savitzky-Golay filter. <code>msc</code> (boolean, default: false) Multiplicative Scatter Correction - corrects for scatter effects by normalizing to a reference spectrum. <code>detrend</code> (boolean, default: false) Remove linear trends from spectra. <p>Preprocessing and Segmentation</p> <p>Heavy preprocessing can reduce segmentation quality. Use <code>minimal</code> for best segmentation results.</p>"},{"location":"getting-started/configuration/#segmentation-settings","title":"Segmentation Settings","text":"<p>Configure seed detection and isolation:</p> <pre><code>segmentation:\n  algorithm: watershed         # Algorithm choice (threshold/watershed/connected/combined)\n  min_pixels: 200             # Minimum seed size in pixels\n  max_pixels: null            # Maximum seed size (null = no limit)\n  reject_overlapping: true    # Reject overlapping seeds\n\n  # Thresholding options\n  threshold_method: otsu      # Method for threshold algorithm (otsu/adaptive/manual)\n\n  # Morphological operations\n  morphology_operations: true # Apply morphological cleanup\n  morphology_kernel_size: 3   # Kernel size for morphology (1-21)\n\n  # Border filtering\n  filter_border_seeds: false  # Remove seeds touching image borders\n  border_width: 2            # Border region width in pixels (0-50)\n\n  # Outlier removal (automatic)\n  remove_outliers: true       # Enable outlier detection\n  outlier_min_area: 50        # Minimum seed area threshold\n  outlier_max_area: 2000      # Maximum seed area threshold\n  outlier_iqr_lower: 1.5      # IQR multiplier for lower bound\n  outlier_iqr_upper: 3.0      # IQR multiplier for upper bound\n\n  # Shape-based filtering (optional)\n  use_shape_filtering: false  # Enable shape-based outlier removal\n  outlier_eccentricity: 0.95  # Maximum eccentricity (elongation, 0-1)\n  outlier_solidity: 0.7       # Minimum solidity (regularity, 0-1)\n</code></pre>"},{"location":"getting-started/configuration/#segmentation-algorithms","title":"Segmentation Algorithms","text":"<code>threshold</code> Simple intensity-based thresholding using Otsu or adaptive methods Pros: Fast, simple | Cons: May not separate touching seeds well <code>watershed</code> (recommended) Watershed segmentation with distance transform Pros: Effectively separates touching seeds | Cons: Slightly slower <code>connected</code> Connected components labeling with shape filtering Pros: Simple, fast for well-separated seeds | Cons: Cannot separate touching seeds <code>combined</code> Combines multiple algorithms using consensus voting Pros: Most robust, best accuracy | Cons: Slowest"},{"location":"getting-started/configuration/#algorithm-parameters","title":"Algorithm Parameters","text":"<code>algorithm</code> (choice, default: \"watershed\") Segmentation algorithm to use. Choose based on your seed arrangement. <code>threshold_method</code> (choice, default: \"otsu\") Thresholding method for threshold algorithm: <ul> <li><code>otsu</code>: Automatic global threshold (recommended)</li> </ul> <ul> <li><code>adaptive</code>: Local adaptive thresholding for uneven illumination</li> </ul> <ul> <li><code>manual</code>: Requires manual threshold value</li> </ul> <code>morphology_operations</code> (boolean, default: true) Apply morphological operations (closing, opening) to clean up segmentation. <code>morphology_kernel_size</code> (int, default: 3, range: 1-21) Size of kernel for morphological operations. Larger values = more aggressive cleanup. <code>filter_border_seeds</code> (boolean, default: false) Remove seeds touching image borders (useful for incomplete seeds at edges). <code>border_width</code> (int, default: 2, range: 0-50) Width of border region to check when filtering border seeds."},{"location":"getting-started/configuration/#size-filtering","title":"Size Filtering","text":"<code>min_pixels</code> (int, default: 200, range: 10-10000) Minimum seed size in pixels. Objects smaller than this are filtered out. <code>max_pixels</code> (int, default: None, range: 10-100000) Maximum seed size in pixels. Objects larger than this are filtered out. Set to <code>null</code> for no upper limit. <code>reject_overlapping</code> (boolean, default: true) Reject seeds that overlap or touch each other. <p>Choosing min_pixels</p> <p>The default of 200 pixels works for most seeds. Adjust based on your imaging resolution: - Small seeds or high resolution: <code>min_pixels: 100</code> - Medium seeds (default): <code>min_pixels: 200</code> - Large seeds or low resolution: <code>min_pixels: 300</code></p>"},{"location":"getting-started/configuration/#outlier-removal","title":"Outlier Removal","text":"<p>Automatic outlier removal uses a three-step process to eliminate: - Reference objects (calibration targets) - Anomalous large/small objects - Debris and artifacts - Irregularly shaped objects (optional)</p> <code>remove_outliers</code> (boolean, default: true) Enable automatic outlier detection and removal. Highly recommended. <p>Step 1: Absolute Area Bounds</p> <code>outlier_min_area</code> (int, default: 50) Minimum area threshold. Seeds below this are always removed. <code>outlier_max_area</code> (int, default: 2000) Maximum area threshold. Seeds above this are always removed. <p>Step 2: IQR-Based Filtering</p> <p>Uses Interquartile Range (IQR) to detect statistical outliers in seed size distribution.</p> <code>outlier_iqr_lower</code> (float, default: 1.5) IQR multiplier for lower bound calculation. Lower bound = Q1 - (iqr_lower \u00d7 IQR) <code>outlier_iqr_upper</code> (float, default: 3.0) IQR multiplier for upper bound calculation. Upper bound = Q3 + (iqr_upper \u00d7 IQR) <p>Asymmetric IQR Multipliers</p> <p>The default uses asymmetric multipliers (1.5 lower, 3.0 upper) because large outliers (reference objects) are more common than small outliers.</p> <p>Step 3: Shape-Based Filtering (Optional)</p> <code>use_shape_filtering</code> (boolean, default: false) Enable shape-based outlier removal. Filters seeds based on eccentricity and solidity. <code>outlier_eccentricity</code> (float, default: 0.95, range: 0-1) Maximum eccentricity (elongation). 0 = circle, 1 = line. Seeds above threshold are removed. <code>outlier_solidity</code> (float, default: 0.7, range: 0-1) Minimum solidity (area/convex hull area). Measures shape regularity. Seeds below threshold are removed."},{"location":"getting-started/configuration/#output-settings","title":"Output Settings","text":"<p>Configure results and visualizations:</p> <pre><code>output:\n  format: csv                  # Output format (currently only csv)\n  include_plots: true          # Generate visualization plots\n  include_coordinates: true    # Include spatial coordinates\n  include_morphology: true     # Include shape properties\n  save_mask: false            # Save segmentation mask\n</code></pre> <code>include_plots</code> (boolean, default: true) Generate distribution, segmentation, and spectral plots. <code>include_coordinates</code> (boolean, default: true) Include centroid coordinates in output CSV. <code>include_morphology</code> (boolean, default: true) Include morphological properties (area, eccentricity, solidity)."},{"location":"getting-started/configuration/#using-configuration-files","title":"Using Configuration Files","text":""},{"location":"getting-started/configuration/#from-command-line","title":"From Command Line","text":"<pre><code># Generate config\nhyperseed config --output my_config.yaml --preset minimal\n\n# Use config for analysis\nhyperseed analyze dataset/sample_001 --config my_config.yaml\n\n# Use config for batch processing\nhyperseed batch dataset/ --config my_config.yaml --output-dir results/\n</code></pre>"},{"location":"getting-started/configuration/#overriding-config-with-cli-arguments","title":"Overriding Config with CLI Arguments","text":"<p>Command-line arguments override configuration file settings:</p> <pre><code># Config file has min_pixels: 50, but override to 100\nhyperseed analyze dataset/sample_001 \\\n    --config my_config.yaml \\\n    --min-pixels 100\n</code></pre>"},{"location":"getting-started/configuration/#example-configurations","title":"Example Configurations","text":""},{"location":"getting-started/configuration/#example-1-high-quality-segmentation","title":"Example 1: High-Quality Segmentation","text":"<pre><code>calibration:\n  apply_calibration: true\n  clip_negative: true\n  clip_max: 1.0\n\npreprocessing:\n  method: minimal\n  smoothing: true\n  smoothing_window: 11\n\nsegmentation:\n  algorithm: watershed\n  min_pixels: 50\n  remove_outliers: true\n\noutput:\n  include_plots: true\n  include_coordinates: true\n</code></pre>"},{"location":"getting-started/configuration/#example-2-advanced-spectral-analysis","title":"Example 2: Advanced Spectral Analysis","text":"<pre><code>calibration:\n  apply_calibration: true\n  clip_negative: true\n  clip_max: 1.0\n\npreprocessing:\n  method: advanced\n  snv: true\n  smoothing: true\n  smoothing_window: 11\n  baseline_correction: true\n  derivative: 1\n\nsegmentation:\n  algorithm: combined\n  min_pixels: 50\n  remove_outliers: true\n\noutput:\n  include_plots: true\n  include_coordinates: true\n  save_mask: true\n</code></pre>"},{"location":"getting-started/configuration/#example-3-fast-batch-processing","title":"Example 3: Fast Batch Processing","text":"<pre><code>calibration:\n  apply_calibration: true\n  clip_negative: true\n\npreprocessing:\n  method: none  # Skip preprocessing for speed\n\nsegmentation:\n  algorithm: threshold  # Fastest algorithm\n  min_pixels: 50\n  remove_outliers: false  # Skip outlier detection\n\noutput:\n  include_plots: false  # Skip plots for speed\n  include_coordinates: true\n</code></pre>"},{"location":"getting-started/configuration/#validation","title":"Validation","text":"<p>Hyperseed validates your configuration and provides helpful error messages:</p> <pre><code>$ hyperseed analyze dataset/sample_001 --config invalid_config.yaml\n\nError: Invalid configuration\n- smoothing_window must be an odd number (got 10)\n- min_pixels must be greater than 0 (got -5)\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand configuration:</p> <ul> <li>User Guide: Learn about specific features</li> <li>Preprocessing Guide: Deep dive into preprocessing methods</li> <li>Segmentation Guide: Deep dive into segmentation algorithms</li> <li>CLI Reference: Complete command documentation</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers different methods to install Hyperseed.</p>"},{"location":"getting-started/installation/#using-pip-recommended","title":"Using pip (Recommended)","text":"<p>The simplest way to install Hyperseed is via pip from PyPI:</p> <pre><code>pip install hyperseed\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify that Hyperseed is installed correctly:</p> <pre><code>hyperseed --version\n</code></pre> <p>You should see output like: <pre><code>Hyperseed version 0.1.0-alpha.3\n</code></pre></p>"},{"location":"getting-started/installation/#using-pip-from-github","title":"Using pip from GitHub","text":"<p>To install the latest development version directly from GitHub:</p> <pre><code>pip install --no-cache-dir --force-reinstall https://github.com/nishad/hyperseed/archive/main.zip\n</code></pre> <p>This method is useful for: - Getting the absolute latest features - Testing bug fixes before they're released - Contributing to development</p>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<p>For development or customization, install from source:</p> <pre><code># 1. Clone the repository\ngit clone https://github.com/nishad/hyperseed\ncd hyperseed\n\n# 2. Create a virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# 3. Install in development mode with dev dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#development-installation-benefits","title":"Development Installation Benefits","text":"<p>Installing with <code>-e \".[dev]\"</code> provides:</p> <ul> <li>Editable mode: Changes to code are immediately available</li> <li>Development tools: Testing, linting, formatting tools included</li> <li>Documentation tools: MkDocs for building these docs</li> </ul>"},{"location":"getting-started/installation/#development-dependencies","title":"Development Dependencies","text":"<p>The development installation includes:</p> <ul> <li>Testing: pytest, pytest-cov, pytest-mock</li> <li>Code Quality: black, ruff, mypy</li> <li>Documentation: mkdocs-material, mkdocstrings</li> <li>Notebooks: jupyter, ipykernel</li> </ul>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#minimum-requirements","title":"Minimum Requirements","text":"Component Requirement Python 3.10 or higher RAM 4GB (minimum) Disk Space 500MB for installation OS macOS, Linux, or Windows"},{"location":"getting-started/installation/#recommended-requirements","title":"Recommended Requirements","text":"Component Recommendation Python 3.11 or 3.12 RAM 8GB+ Disk Space 2GB+ for data and results CPU Multi-core for batch processing"},{"location":"getting-started/installation/#virtual-environments","title":"Virtual Environments","text":"<p>We strongly recommend using a virtual environment to avoid dependency conflicts.</p>"},{"location":"getting-started/installation/#using-venv-built-in","title":"Using venv (built-in)","text":"<pre><code># Create environment\npython -m venv hyperseed-env\n\n# Activate (macOS/Linux)\nsource hyperseed-env/bin/activate\n\n# Activate (Windows)\nhyperseed-env\\Scripts\\activate\n\n# Install hyperseed\npip install hyperseed\n</code></pre>"},{"location":"getting-started/installation/#using-conda","title":"Using conda","text":"<pre><code># Create environment\nconda create -n hyperseed python=3.11\n\n# Activate\nconda activate hyperseed\n\n# Install hyperseed\npip install hyperseed\n</code></pre>"},{"location":"getting-started/installation/#updating-hyperseed","title":"Updating Hyperseed","text":"<p>To update to the latest version:</p> <pre><code>pip install --upgrade hyperseed\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<p>To remove Hyperseed:</p> <pre><code>pip uninstall hyperseed\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"Error: Python version not supported <p>Hyperseed requires Python 3.10+. Check your Python version: <pre><code>python --version\n</code></pre></p> <p>If needed, install a newer Python version from python.org.</p> Error: Permission denied <p>On macOS/Linux, you may need to use: <pre><code>pip install --user hyperseed\n</code></pre></p> <p>Or use a virtual environment (recommended).</p> Error: Could not find a version that satisfies the requirement <p>Update pip to the latest version: <pre><code>pip install --upgrade pip\n</code></pre></p> Installation is very slow <p>Some dependencies (like NumPy, SciPy) can be large. Consider:</p> <ul> <li>Using a wired internet connection</li> <li>Installing with conda if you have it available</li> <li>Using a mirror closer to your location</li> </ul>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check GitHub Issues for similar problems</li> <li>Create a new issue with:<ul> <li>Your OS and Python version</li> <li>Complete error message</li> <li>Installation method you tried</li> </ul> </li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, proceed to the Quick Start Guide \u2192</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get started with Hyperseed in 5 minutes! This guide walks you through your first analysis.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li> Installed Hyperseed (<code>pip install hyperseed</code>)</li> <li> Hyperspectral data in ENVI format with white/dark references</li> </ul>"},{"location":"getting-started/quick-start/#your-first-analysis","title":"Your First Analysis","text":""},{"location":"getting-started/quick-start/#step-1-prepare-your-data","title":"Step 1: Prepare Your Data","text":"<p>Ensure your dataset follows this structure:</p> <pre><code>dataset/sample_001/\n\u251c\u2500\u2500 capture/\n\u2502   \u251c\u2500\u2500 data.raw              # Main hyperspectral data\n\u2502   \u251c\u2500\u2500 data.hdr              # ENVI header file\n\u2502   \u251c\u2500\u2500 WHITEREF_data.raw     # White reference\n\u2502   \u251c\u2500\u2500 WHITEREF_data.hdr\n\u2502   \u251c\u2500\u2500 DARKREF_data.raw      # Dark reference\n\u2502   \u2514\u2500\u2500 DARKREF_data.hdr\n</code></pre> <p>Data Structure</p> <p>See Data Preparation for detailed information about expected data structure.</p>"},{"location":"getting-started/quick-start/#step-2-run-basic-analysis","title":"Step 2: Run Basic Analysis","text":"<p>Run your first analysis with default settings:</p> <pre><code>hyperseed analyze dataset/sample_001 --output results.csv\n</code></pre> <p>This command: - \u2705 Loads the hyperspectral data - \u2705 Applies automatic calibration - \u2705 Segments individual seeds - \u2705 Extracts spectral signatures - \u2705 Saves results to <code>results.csv</code></p>"},{"location":"getting-started/quick-start/#step-3-view-results","title":"Step 3: View Results","text":"<p>The analysis generates a CSV file with spectral data:</p> <pre><code>seed_id,index,centroid_y,centroid_x,area,eccentricity,solidity,band_1000nm,band_1005nm,...\n1,0,234.5,156.2,435,0.34,0.92,0.234,0.237,...\n2,1,345.6,234.1,421,0.28,0.94,0.229,0.232,...\n</code></pre> <p>Each row represents one seed with: - Spatial information: centroid coordinates - Morphological properties: area, eccentricity, solidity - Spectral data: reflectance values for each wavelength band</p>"},{"location":"getting-started/quick-start/#adding-visualizations","title":"Adding Visualizations","text":"<p>To generate plots along with the CSV data:</p> <pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --export-plots\n</code></pre> <p>This creates four visualization files:</p> <ol> <li><code>sample_001_distribution.png</code>: Spatial and area distribution</li> <li><code>sample_001_segmentation.png</code>: Numbered seeds with boundaries</li> <li><code>sample_001_spectra.png</code>: Individual spectral curves</li> <li><code>sample_001_spectra_statistics.png</code>: Statistical analysis</li> </ol> <p>Recommended First Run</p> <p>Always use <code>--export-plots</code> on your first analysis to visually verify the segmentation quality.</p>"},{"location":"getting-started/quick-start/#recommended-settings","title":"Recommended Settings","text":"<p>For optimal results with seed analysis:</p> <pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --min-pixels 50 \\\n    --preprocess minimal \\\n    --export-plots\n</code></pre> <p>Parameters explained:</p> <ul> <li><code>--min-pixels 50</code>: Filter out objects smaller than 50 pixels (reduces noise)</li> <li><code>--preprocess minimal</code>: Light preprocessing optimized for segmentation</li> <li><code>--export-plots</code>: Generate visualization plots</li> </ul>"},{"location":"getting-started/quick-start/#batch-processing","title":"Batch Processing","text":"<p>To process multiple datasets:</p> <pre><code># Process all datasets in the directory\nhyperseed batch dataset/ \\\n    --output-dir results/ \\\n    --min-pixels 50\n</code></pre> <p>This will: - Process all subdirectories in <code>dataset/</code> - Save results to <code>results/</code> directory - Apply consistent settings to all datasets</p>"},{"location":"getting-started/quick-start/#common-options","title":"Common Options","text":"<p>Here are the most commonly used options:</p> Option Description Example <code>--output</code> Output CSV file path <code>results.csv</code> <code>--export-plots</code> Generate visualization plots (flag) <code>--min-pixels</code> Minimum seed size in pixels <code>50</code> <code>--preprocess</code> Preprocessing method <code>minimal</code>, <code>standard</code>, <code>advanced</code>, <code>none</code> <code>--no-outlier-removal</code> Disable automatic outlier removal (flag) <code>--config</code> Use custom configuration file <code>config.yaml</code>"},{"location":"getting-started/quick-start/#whats-next","title":"What's Next?","text":""},{"location":"getting-started/quick-start/#customize-your-analysis","title":"Customize Your Analysis","text":"<p>Learn how to create custom configurations:</p> <pre><code># Generate a configuration template\nhyperseed config --output my_config.yaml --preset minimal\n\n# Use your custom configuration\nhyperseed analyze dataset/sample_001 --config my_config.yaml\n</code></pre> <p>See Configuration Guide \u2192</p>"},{"location":"getting-started/quick-start/#advanced-workflows","title":"Advanced Workflows","text":"<p>Explore advanced features:</p> <ul> <li>Preprocessing Options: SNV, derivatives, baseline correction</li> <li>Segmentation Algorithms: Threshold, watershed, combined methods</li> <li>Batch Processing: Processing multiple datasets efficiently</li> </ul>"},{"location":"getting-started/quick-start/#command-line-reference","title":"Command-Line Reference","text":"<p>For complete command documentation:</p> <ul> <li>CLI Reference: All commands and options</li> <li>Analyze Command: Detailed analysis options</li> <li>Batch Command: Batch processing guide</li> </ul>"},{"location":"getting-started/quick-start/#example-complete-workflow","title":"Example: Complete Workflow","text":"<p>Here's a complete example workflow:</p> <pre><code># 1. Analyze a single dataset with visualizations\nhyperseed analyze dataset/sample_001 \\\n    --output results/sample_001.csv \\\n    --min-pixels 50 \\\n    --preprocess minimal \\\n    --export-plots\n\n# 2. Review the plots and adjust if needed\n\n# 3. Process all datasets with the same settings\nhyperseed batch dataset/ \\\n    --output-dir results/ \\\n    --min-pixels 50 \\\n    --preprocess minimal\n\n# 4. Results are now in results/ directory\nls results/\n# sample_001.csv  sample_002.csv  sample_003.csv  ...\n</code></pre>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<p>Need assistance?</p> <pre><code># Get general help\nhyperseed --help\n\n# Get help for specific command\nhyperseed analyze --help\nhyperseed batch --help\n</code></pre> <p>Or check the Troubleshooting Guide for common issues.</p> <p>Congratulations! You've completed your first Hyperseed analysis. Continue to the Configuration Guide to learn about customization options.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Comprehensive documentation for using Hyperseed's features and workflows.</p>"},{"location":"user-guide/#overview","title":"Overview","text":"<p>This user guide covers all aspects of hyperspectral seed analysis with Hyperseed, from data preparation to advanced workflows.</p>"},{"location":"user-guide/#topics","title":"Topics","text":"<ul> <li> <p> Data Preparation</p> <p>Learn about expected data structure and ENVI format requirements</p> </li> <li> <p> Preprocessing</p> <p>Understand spectral preprocessing methods and when to use them</p> </li> <li> <p> Segmentation</p> <p>Explore segmentation algorithms and optimize seed detection</p> </li> <li> <p> Batch Processing</p> <p>Process multiple datasets efficiently</p> </li> <li> <p> Troubleshooting</p> <p>Solutions to common issues and error messages</p> </li> </ul>"},{"location":"user-guide/#typical-workflows","title":"Typical Workflows","text":""},{"location":"user-guide/#basic-workflow","title":"Basic Workflow","text":"<pre><code>graph LR\n    A[Prepare Data] --&gt; B[Run Analysis]\n    B --&gt; C[Review Plots]\n    C --&gt; D[Export Results]</code></pre> <ol> <li>Ensure data is in correct format</li> <li>Run analysis with <code>--export-plots</code></li> <li>Review segmentation quality</li> <li>Export final results</li> </ol>"},{"location":"user-guide/#advanced-workflow","title":"Advanced Workflow","text":"<pre><code>graph LR\n    A[Prepare Data] --&gt; B[Test Config]\n    B --&gt; C{Satisfied?}\n    C --&gt;|No| D[Adjust Settings]\n    D --&gt; B\n    C --&gt;|Yes| E[Batch Process]\n    E --&gt; F[Export Results]</code></pre> <ol> <li>Prepare data and create configuration</li> <li>Test on single dataset</li> <li>Iteratively adjust preprocessing and segmentation</li> <li>Batch process all datasets</li> <li>Export and analyze results</li> </ol>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#for-best-segmentation","title":"For Best Segmentation","text":"<ol> <li>Use minimal preprocessing for segmentation</li> <li>Set appropriate min_pixels based on seed size</li> <li>Enable outlier removal to filter artifacts</li> <li>Use watershed algorithm for touching seeds</li> <li>Always review plots first before batch processing</li> </ol>"},{"location":"user-guide/#for-spectral-analysis","title":"For Spectral Analysis","text":"<ol> <li>Apply appropriate preprocessing (SNV, smoothing, derivatives)</li> <li>Use calibrated data (not preprocessed data) for final spectra</li> <li>Check for bad pixels in reference images</li> <li>Validate wavelength calibration in header files</li> <li>Document preprocessing steps for reproducibility</li> </ol>"},{"location":"user-guide/#common-use-cases","title":"Common Use Cases","text":""},{"location":"user-guide/#use-case-1-quick-seed-count","title":"Use Case 1: Quick Seed Count","text":"<pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --min-pixels 50\n</code></pre> <p>Result: CSV with seed count and basic morphology</p>"},{"location":"user-guide/#use-case-2-detailed-spectral-analysis","title":"Use Case 2: Detailed Spectral Analysis","text":"<pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --preprocess advanced \\\n    --export-plots\n</code></pre> <p>Result: CSV with preprocessed spectra + visualization plots</p>"},{"location":"user-guide/#use-case-3-production-batch-processing","title":"Use Case 3: Production Batch Processing","text":"<pre><code>hyperseed batch dataset/ \\\n    --output-dir results/ \\\n    --config production_config.yaml\n</code></pre> <p>Result: Consistent analysis across all datasets</p>"},{"location":"user-guide/#need-more-help","title":"Need More Help?","text":"<ul> <li>Quick answers: Check Troubleshooting</li> <li>Command details: See CLI Reference</li> <li>API usage: See API Reference</li> <li>Report bugs: GitHub Issues</li> </ul>"},{"location":"user-guide/batch-processing/","title":"Batch Processing","text":"<p>Process multiple hyperspectral datasets efficiently with consistent settings.</p>"},{"location":"user-guide/batch-processing/#overview","title":"Overview","text":"<p>Batch processing allows you to analyze multiple hyperspectral datasets with the same analysis pipeline. The <code>batch</code> command:</p> <ul> <li>Processes datasets sequentially (one after another)</li> <li>Applies consistent settings across all datasets</li> <li>Handles errors gracefully - continues if one dataset fails</li> <li>Generates organized output with clear naming</li> <li>Provides progress feedback and summary statistics</li> </ul>"},{"location":"user-guide/batch-processing/#when-to-use-batch-processing","title":"When to Use Batch Processing","text":""},{"location":"user-guide/batch-processing/#good-use-cases","title":"Good Use Cases","text":"<p>\u2705 Processing experimental datasets <pre><code># Process all treatment groups\nhyperseed batch experiments/treatment_A/ --config settings.yaml\nhyperseed batch experiments/treatment_B/ --config settings.yaml\n</code></pre></p> <p>\u2705 Consistent analysis across time points <pre><code># Process all time points with same settings\nhyperseed batch timeseries/ --pattern \"day_*\" --output-dir results/\n</code></pre></p> <p>\u2705 Quality control across samples <pre><code># Quick batch analysis of all samples\nhyperseed batch samples/ --config minimal_config.yaml\n</code></pre></p> <p>\u2705 Re-analyzing with different parameters <pre><code># First pass\nhyperseed batch datasets/ --config pass1.yaml --output-dir results_v1/\n\n# Second pass with adjusted settings\nhyperseed batch datasets/ --config pass2.yaml --output-dir results_v2/\n</code></pre></p>"},{"location":"user-guide/batch-processing/#not-recommended","title":"Not Recommended","text":"<p>\u274c Single dataset - Use <code>analyze</code> command instead <pre><code># Don't use batch for one dataset\nhyperseed analyze dataset/sample_001 --output results.csv\n</code></pre></p> <p>\u274c Different settings per dataset - Process individually <pre><code># Process each with different config\nhyperseed analyze dataset/sample_001 --config config_A.yaml\nhyperseed analyze dataset/sample_002 --config config_B.yaml\n</code></pre></p> <p>\u274c Interactive parameter tuning - Use <code>segment</code> or <code>analyze</code> <pre><code># Use analyze for testing parameters\nhyperseed analyze dataset/sample --min-pixels 100 --export-plots\nhyperseed analyze dataset/sample --min-pixels 200 --export-plots\n</code></pre></p>"},{"location":"user-guide/batch-processing/#quick-start","title":"Quick Start","text":""},{"location":"user-guide/batch-processing/#basic-batch-processing","title":"Basic Batch Processing","text":"<pre><code># Process all datasets in directory\nhyperseed batch datasets/\n</code></pre> <p>What happens: 1. Finds all subdirectories in <code>datasets/</code> 2. Processes each sequentially 3. Saves results to <code>datasets/results/</code></p>"},{"location":"user-guide/batch-processing/#with-custom-output","title":"With Custom Output","text":"<pre><code>hyperseed batch datasets/ --output-dir analysis_results/\n</code></pre>"},{"location":"user-guide/batch-processing/#with-configuration","title":"With Configuration","text":"<pre><code>hyperseed batch datasets/ \\\n    --config batch_config.yaml \\\n    --output-dir results/\n</code></pre>"},{"location":"user-guide/batch-processing/#directory-structure","title":"Directory Structure","text":""},{"location":"user-guide/batch-processing/#input-structure-required","title":"Input Structure Required","text":"<pre><code>datasets/\n\u251c\u2500\u2500 sample_001/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u251c\u2500\u2500 data.raw\n\u2502       \u251c\u2500\u2500 data.hdr\n\u2502       \u251c\u2500\u2500 WHITEREF_data.raw\n\u2502       \u251c\u2500\u2500 WHITEREF_data.hdr\n\u2502       \u251c\u2500\u2500 DARKREF_data.raw\n\u2502       \u2514\u2500\u2500 DARKREF_data.hdr\n\u251c\u2500\u2500 sample_002/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_003/\n    \u2514\u2500\u2500 capture/\n        \u2514\u2500\u2500 ...\n</code></pre> <p>Requirements: - Each dataset must be in its own subdirectory - Each must have a <code>capture/</code> folder - Must contain <code>data.hdr</code>, white reference, dark reference</p>"},{"location":"user-guide/batch-processing/#output-structure-generated","title":"Output Structure Generated","text":"<pre><code>results/\n\u251c\u2500\u2500 sample_001_spectra.csv\n\u251c\u2500\u2500 sample_001_distribution.png\n\u251c\u2500\u2500 sample_001_segmentation.png\n\u251c\u2500\u2500 sample_001_spectra.png\n\u251c\u2500\u2500 sample_002_spectra.csv\n\u251c\u2500\u2500 sample_002_distribution.png\n\u251c\u2500\u2500 sample_002_segmentation.png\n\u251c\u2500\u2500 sample_002_spectra.png\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"user-guide/batch-processing/#configuration-for-batch-processing","title":"Configuration for Batch Processing","text":""},{"location":"user-guide/batch-processing/#creating-a-batch-configuration","title":"Creating a Batch Configuration","text":"<pre><code># Generate template\nhyperseed config --output batch_config.yaml --preset minimal\n</code></pre>"},{"location":"user-guide/batch-processing/#recommended-batch-settings","title":"Recommended Batch Settings","text":"<pre><code># batch_config.yaml - Optimized for batch processing\n\ncalibration:\n  apply_calibration: true\n  clip_negative: true\n  clip_max: 1.0\n  interpolate_bad_pixels: true\n\npreprocessing:\n  method: minimal  # Fast, good for segmentation\n\nsegmentation:\n  algorithm: watershed  # Best balance\n  min_pixels: 200\n  reject_overlapping: true\n  remove_outliers: true  # Automatic quality control\n  outlier_min_area: 50\n  outlier_max_area: 2000\n</code></pre>"},{"location":"user-guide/batch-processing/#fast-batch-configuration","title":"Fast Batch Configuration","text":"<p>For maximum speed when processing many datasets:</p> <pre><code># fast_batch.yaml - Speed-optimized\n\npreprocessing:\n  method: none  # Skip preprocessing\n\nsegmentation:\n  algorithm: threshold  # Fastest algorithm\n  min_pixels: 200\n  morphology_operations: false\n  remove_outliers: false\n</code></pre> <pre><code>hyperseed batch large_dataset/ --config fast_batch.yaml\n</code></pre>"},{"location":"user-guide/batch-processing/#pattern-matching","title":"Pattern Matching","text":"<p>Use glob patterns to selectively process datasets.</p>"},{"location":"user-guide/batch-processing/#match-all-default","title":"Match All (Default)","text":"<pre><code>hyperseed batch datasets/\n# Processes: sample_001, sample_002, sample_003, ...\n</code></pre>"},{"location":"user-guide/batch-processing/#match-prefix","title":"Match Prefix","text":"<pre><code># Process only datasets starting with \"SWIR_\"\nhyperseed batch datasets/ --pattern \"SWIR_*\"\n# Processes: SWIR_001, SWIR_002, SWIR_003\n# Skips: VIS_001, other_data\n</code></pre>"},{"location":"user-guide/batch-processing/#match-specific-range","title":"Match Specific Range","text":"<pre><code># Process samples 1-5\nhyperseed batch datasets/ --pattern \"sample_00[1-5]\"\n# Processes: sample_001, sample_002, ..., sample_005\n# Skips: sample_006, sample_007, ...\n</code></pre>"},{"location":"user-guide/batch-processing/#match-multiple-patterns","title":"Match Multiple Patterns","text":"<pre><code># Process treatment A samples\nhyperseed batch experiments/ --pattern \"A_*\"\n\n# Then process treatment B samples\nhyperseed batch experiments/ --pattern \"B_*\" --output-dir results_B/\n</code></pre>"},{"location":"user-guide/batch-processing/#complex-patterns","title":"Complex Patterns","text":"<pre><code># Process all SWIR samples from experiment 1\nhyperseed batch data/ --pattern \"exp1_SWIR_*\"\n\n# Process time point zero across all experiments\nhyperseed batch data/ --pattern \"*_t00_*\"\n</code></pre>"},{"location":"user-guide/batch-processing/#error-handling","title":"Error Handling","text":"<p>Batch processing continues even when individual datasets fail.</p>"},{"location":"user-guide/batch-processing/#example-output-with-failures","title":"Example Output with Failures","text":"<pre><code>$ hyperseed batch datasets/ --output-dir results/\n\n[1/5] Processing sample_001...\n  \u2713 Processed: 47 seeds \u2192 sample_001_spectra.csv\n     Generated visualizations:\n       - sample_001_distribution.png (spatial &amp; size)\n       - sample_001_segmentation.png (numbered seeds)\n       - sample_001_spectra.png (spectral data)\n\n[2/5] Processing sample_002...\n  \u2717 Failed: ENVI header file not found\n\n[3/5] Processing sample_003...\n  \u26a0 No seeds found in sample_003 (check min-pixels threshold)\n\n[4/5] Processing sample_004...\n  \u2713 Processed: 52 seeds \u2192 sample_004_spectra.csv\n\n[5/5] Processing sample_005...\n  \u2713 Processed: 39 seeds \u2192 sample_005_spectra.csv\n\nBatch Processing Summary:\n  Successful: 3/5\n  Failed: sample_002, sample_003\n</code></pre>"},{"location":"user-guide/batch-processing/#common-failure-reasons","title":"Common Failure Reasons","text":"<p>Missing files: <pre><code>Error: ENVI header file not found\n</code></pre> Solution: Check dataset structure, ensure <code>capture/data.hdr</code> exists</p> <p>Corrupted data: <pre><code>Error: Unable to read ENVI data\n</code></pre> Solution: Verify data files are not corrupted, check file permissions</p> <p>No seeds detected: <pre><code>\u26a0 No seeds found (check min-pixels threshold)\n</code></pre> Solution: Lower <code>--min-pixels</code> threshold or check image quality</p>"},{"location":"user-guide/batch-processing/#debugging-failed-datasets","title":"Debugging Failed Datasets","text":"<pre><code># Test failed dataset individually\nhyperseed analyze datasets/sample_002 --output test.csv -v\n\n# Run batch with debug mode\nhyperseed batch datasets/ --debug --output-dir results/\n</code></pre>"},{"location":"user-guide/batch-processing/#performance-and-timing","title":"Performance and Timing","text":""},{"location":"user-guide/batch-processing/#typical-processing-times","title":"Typical Processing Times","text":"<p>Per dataset (typical seed image): - Calibration: ~5-10 seconds - Preprocessing: ~2-5 seconds - Segmentation: ~5-10 seconds - Extraction: ~3-5 seconds - Plotting: ~5-10 seconds - Total: ~30-60 seconds per dataset</p> <p>Batch processing time: <pre><code>Total time \u2248 Number of datasets \u00d7 Time per dataset\n\nExamples:\n- 10 datasets \u00d7 45 sec = ~7.5 minutes\n- 50 datasets \u00d7 45 sec = ~38 minutes\n- 100 datasets \u00d7 45 sec = ~75 minutes\n</code></pre></p>"},{"location":"user-guide/batch-processing/#speed-optimization","title":"Speed Optimization","text":"<p>1. Use minimal preprocessing <pre><code>preprocessing:\n  method: minimal  # 2-3x faster than advanced\n</code></pre></p> <p>2. Use faster segmentation <pre><code>segmentation:\n  algorithm: threshold  # Faster than watershed\n</code></pre></p> <p>3. Disable outlier removal <pre><code>hyperseed batch datasets/ --no-outlier-removal\n</code></pre></p> <p>Combined fast configuration: <pre><code>preprocessing:\n  method: none\n\nsegmentation:\n  algorithm: threshold\n  morphology_operations: false\n  remove_outliers: false\n</code></pre></p> <p>Speed improvement: ~2-3x faster (20-30 seconds per dataset)</p>"},{"location":"user-guide/batch-processing/#workflow-examples","title":"Workflow Examples","text":""},{"location":"user-guide/batch-processing/#example-1-research-experiment","title":"Example 1: Research Experiment","text":"<p>Process multiple treatment groups with consistent settings.</p> <pre><code># Create configuration\ncat &gt; experiment_config.yaml &lt;&lt; EOF\npreprocessing:\n  method: minimal\n\nsegmentation:\n  algorithm: watershed\n  min_pixels: 200\n  remove_outliers: true\nEOF\n\n# Process each treatment group\nfor group in control treatment_A treatment_B; do\n    hyperseed batch experiments/$group/ \\\n        --config experiment_config.yaml \\\n        --output-dir results/$group/\ndone\n\n# Compare results\nls results/*/sample_*.csv\n</code></pre>"},{"location":"user-guide/batch-processing/#example-2-time-series-analysis","title":"Example 2: Time Series Analysis","text":"<p>Process all time points with same settings.</p> <pre><code># Process all time points\nhyperseed batch timeseries/ \\\n    --pattern \"day_*\" \\\n    --config timeseries_config.yaml \\\n    --output-dir timeseries_results/\n\n# Results organized by day\nls timeseries_results/day_*_spectra.csv\n</code></pre>"},{"location":"user-guide/batch-processing/#example-3-quality-control","title":"Example 3: Quality Control","text":"<p>Quick batch processing to identify problem datasets.</p> <pre><code># Fast processing with minimal settings\nhyperseed batch samples/ \\\n    --config minimal_config.yaml \\\n    --output-dir qc_results/ \\\n    -v\n\n# Review which samples failed\ngrep \"Failed\" qc_results/*.log\n\n# Check seed counts\nfor f in qc_results/*_spectra.csv; do\n    echo \"$f: $(wc -l &lt; $f) seeds\"\ndone\n</code></pre>"},{"location":"user-guide/batch-processing/#example-4-re-analysis-with-different-parameters","title":"Example 4: Re-analysis with Different Parameters","text":"<p>Compare results with different min_pixels thresholds.</p> <pre><code># First pass - default\nhyperseed batch datasets/ \\\n    --min-pixels 200 \\\n    --output-dir results_p200/\n\n# Second pass - lower threshold\nhyperseed batch datasets/ \\\n    --min-pixels 100 \\\n    --output-dir results_p100/\n\n# Compare seed counts\ndiff &lt;(ls results_p200/*.csv | wc -l) \\\n     &lt;(ls results_p100/*.csv | wc -l)\n</code></pre>"},{"location":"user-guide/batch-processing/#example-5-selective-re-processing","title":"Example 5: Selective Re-processing","text":"<p>Re-process only failed datasets.</p> <pre><code># Initial batch run\nhyperseed batch datasets/ --output-dir results/\n\n# Identify successful datasets\nsuccessful=$(ls results/*_spectra.csv | xargs -n1 basename | sed 's/_spectra.csv//')\n\n# Find failed datasets\ncd datasets/\nfor dataset in *; do\n    if ! echo \"$successful\" | grep -q \"$dataset\"; then\n        echo \"Failed: $dataset\"\n    fi\ndone\n\n# Re-process failed datasets manually\nhyperseed analyze datasets/failed_sample_002 --output results/failed_sample_002_spectra.csv\n</code></pre>"},{"location":"user-guide/batch-processing/#monitoring-progress","title":"Monitoring Progress","text":""},{"location":"user-guide/batch-processing/#real-time-monitoring","title":"Real-time Monitoring","text":"<pre><code># Terminal 1: Run batch processing\nhyperseed batch datasets/ --output-dir results/ -v\n\n# Terminal 2: Monitor output files\nwatch -n 5 'ls -lh results/*.csv | wc -l'\n\n# Terminal 3: Monitor disk usage\nwatch -n 10 'du -sh results/'\n</code></pre>"},{"location":"user-guide/batch-processing/#progress-estimation","title":"Progress Estimation","text":"<pre><code># Count total datasets\ntotal=$(ls -d datasets/*/ | wc -l)\n\n# Monitor completion\nwhile true; do\n    completed=$(ls results/*_spectra.csv 2&gt;/dev/null | wc -l)\n    echo \"Progress: $completed / $total\"\n    sleep 10\ndone\n</code></pre>"},{"location":"user-guide/batch-processing/#batch-vs-individual-analysis","title":"Batch vs. Individual Analysis","text":"Aspect batch command analyze command Number of datasets Multiple Single Processing Sequential One-time Settings Consistent across all Per-run Error handling Continues on failure Stops on error Progress display Dataset count (1/N) Detailed progress bar Output organization All in one directory Specified per run Interactive tuning Not suitable Good for testing Automation Excellent Requires scripting <p>Use batch when: - Processing 3+ datasets with same settings - Need consistent analysis pipeline - Running automated workflows - Don't need to test parameters</p> <p>Use analyze when: - Processing single dataset - Testing different parameters - Need detailed progress feedback - Want to inspect results interactively</p>"},{"location":"user-guide/batch-processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/batch-processing/#issue-no-datasets-found","title":"Issue: No datasets found","text":"<p>Error: <code>No datasets found matching '*'</code></p> <p>Causes: - Wrong directory structure - No <code>capture/</code> folders - Pattern doesn't match</p> <p>Solutions: <pre><code># Check structure\nls -la datasets/\n\n# Verify capture folders\nfind datasets/ -type d -name \"capture\"\n\n# Try explicit pattern\nhyperseed batch datasets/ --pattern \"*\" -v\n</code></pre></p>"},{"location":"user-guide/batch-processing/#issue-all-datasets-failing","title":"Issue: All datasets failing","text":"<p>Solutions: <pre><code># Test one dataset individually\nhyperseed analyze datasets/sample_001 --output test.csv -v\n\n# Check data files\nls datasets/sample_001/capture/\n\n# Run with debug\nhyperseed batch datasets/ --debug\n</code></pre></p>"},{"location":"user-guide/batch-processing/#issue-inconsistent-seed-counts","title":"Issue: Inconsistent seed counts","text":"<p>Possible causes: - Variable image quality - min_pixels threshold not appropriate - Outlier removal too aggressive</p> <p>Solutions: <pre><code># Disable outlier removal to see raw counts\nhyperseed batch datasets/ --no-outlier-removal\n\n# Lower min_pixels\nhyperseed batch datasets/ --min-pixels 100\n\n# Use custom config with looser thresholds\n</code></pre></p>"},{"location":"user-guide/batch-processing/#issue-memory-errors","title":"Issue: Memory errors","text":"<p>Solutions: <pre><code># Process fewer datasets at once\nhyperseed batch datasets/ --pattern \"sample_00[1-3]\"\nhyperseed batch datasets/ --pattern \"sample_00[4-6]\"\n\n# Close other applications\n# Check available memory: free -h (Linux) or top (macOS)\n</code></pre></p>"},{"location":"user-guide/batch-processing/#issue-slow-processing","title":"Issue: Slow processing","text":"<p>Solutions: <pre><code># Use fast configuration\nhyperseed batch datasets/ --config fast_config.yaml\n\n# Skip plots\nhyperseed batch datasets/ --config no_plots.yaml\n\n# Process in chunks\n</code></pre></p>"},{"location":"user-guide/batch-processing/#see-also","title":"See Also","text":"<ul> <li>CLI Reference: batch: Complete command documentation</li> <li>Configuration Guide: Create batch configurations</li> <li>analyze command: Single dataset analysis</li> <li>Segmentation Guide: Optimize segmentation settings</li> </ul>"},{"location":"user-guide/data-preparation/","title":"Data Preparation","text":"<p>Learn how to prepare hyperspectral data for analysis with Hyperseed.</p>"},{"location":"user-guide/data-preparation/#expected-data-structure","title":"Expected Data Structure","text":"<p>Hyperseed expects hyperspectral data in ENVI format with specific file organization:</p> <pre><code>dataset/\n\u2514\u2500\u2500 sample_name/\n    \u251c\u2500\u2500 capture/\n    \u2502   \u251c\u2500\u2500 data.raw              # Main hyperspectral datacube\n    \u2502   \u251c\u2500\u2500 data.hdr              # ENVI header file\n    \u2502   \u251c\u2500\u2500 WHITEREF_data.raw     # White reference\n    \u2502   \u251c\u2500\u2500 WHITEREF_data.hdr\n    \u2502   \u251c\u2500\u2500 DARKREF_data.raw      # Dark reference\n    \u2502   \u2514\u2500\u2500 DARKREF_data.hdr\n    \u251c\u2500\u2500 calibrations/bpr/         # Optional: bad pixel maps\n    \u2502   \u251c\u2500\u2500 bprmap.bpr\n    \u2502   \u2514\u2500\u2500 bprmap.hdr\n    \u2514\u2500\u2500 metadata/                 # Optional: metadata\n        \u2514\u2500\u2500 data.xml\n</code></pre>"},{"location":"user-guide/data-preparation/#required-files","title":"Required Files","text":""},{"location":"user-guide/data-preparation/#main-data-files","title":"Main Data Files","text":"<code>data.raw</code> (required) Binary file containing the hyperspectral datacube (Y \u00d7 X \u00d7 Wavelengths) <code>data.hdr</code> (required) ENVI header file with metadata (dimensions, wavelengths, data type)"},{"location":"user-guide/data-preparation/#reference-files","title":"Reference Files","text":"<code>WHITEREF_data.raw</code> (required) White reference image for reflectance calibration <code>WHITEREF_data.hdr</code> (required) Header file for white reference <code>DARKREF_data.raw</code> (required) Dark reference image for reflectance calibration <code>DARKREF_data.hdr</code> (required) Header file for dark reference <p>Reference Requirements</p> <p>White and dark references are required for reflectance calibration. Without them, analysis cannot proceed.</p>"},{"location":"user-guide/data-preparation/#envi-format","title":"ENVI Format","text":""},{"location":"user-guide/data-preparation/#what-is-envi-format","title":"What is ENVI Format?","text":"<p>ENVI (Environment for Visualizing Images) is a standard format for hyperspectral data consisting of:</p> <ol> <li>Binary data file (<code>.raw</code>, <code>.dat</code>, or no extension)</li> <li>ASCII header file (<code>.hdr</code>)</li> </ol>"},{"location":"user-guide/data-preparation/#header-file-structure","title":"Header File Structure","text":"<p>A minimal ENVI header contains:</p> <pre><code>ENVI\nsamples = 640\nlines = 480\nbands = 224\nheader offset = 0\nfile type = ENVI Standard\ndata type = 4\ninterleave = bil\nbyte order = 0\nwavelength = {\n 1000.0, 1005.0, 1010.0, ...\n}\n</code></pre> <p>Important parameters:</p> <code>samples</code> Number of pixels per line (X dimension) <code>lines</code> Number of lines (Y dimension) <code>bands</code> Number of spectral bands (wavelengths) <code>data type</code> Data format (1=byte, 2=int16, 4=float32, etc.) <code>interleave</code> Data organization (BIL, BIP, or BSQ) <code>wavelength</code> List of wavelengths in nanometers"},{"location":"user-guide/data-preparation/#supported-configurations","title":"Supported Configurations","text":""},{"location":"user-guide/data-preparation/#data-types","title":"Data Types","text":"<p>Hyperseed supports these ENVI data types:</p> Data Type Description Typical Use 1 8-bit unsigned integer Raw sensor data 2 16-bit signed integer Raw sensor data 4 32-bit float Reflectance data 5 64-bit float High-precision reflectance 12 16-bit unsigned integer Raw sensor data"},{"location":"user-guide/data-preparation/#interleave-formats","title":"Interleave Formats","text":"<p>All three interleave formats are supported:</p> BIL (Band Interleaved by Line) (recommended) <code>[band1_line1, band2_line1, ..., band1_line2, band2_line2, ...]</code> Most common for pushbroom sensors BIP (Band Interleaved by Pixel) <code>[band1_pixel1, band2_pixel1, ..., band1_pixel2, band2_pixel2, ...]</code> Good for per-pixel processing BSQ (Band Sequential) <code>[all_band1, all_band2, all_band3, ...]</code> Good for band-wise processing"},{"location":"user-guide/data-preparation/#data-from-specim-cameras","title":"Data from Specim Cameras","text":"<p>Hyperseed is optimized for Specim SWIR cameras but works with any ENVI-format data.</p>"},{"location":"user-guide/data-preparation/#specim-data-export","title":"Specim Data Export","text":"<p>When exporting from Specim software:</p> <ol> <li>\u2705 Export in ENVI format</li> <li>\u2705 Include white reference image</li> <li>\u2705 Include dark reference image</li> <li>\u2705 Export wavelength calibration in header</li> <li>\u2705 Export bad pixel map (optional but recommended)</li> </ol>"},{"location":"user-guide/data-preparation/#typical-specim-wavelength-ranges","title":"Typical Specim Wavelength Ranges","text":"Camera Wavelength Range Spectral Resolution FX10 400-1000 nm ~5 nm FX17 900-1700 nm ~8 nm FX50 1000-2500 nm ~10 nm"},{"location":"user-guide/data-preparation/#verifying-your-data","title":"Verifying Your Data","text":""},{"location":"user-guide/data-preparation/#check-file-structure","title":"Check File Structure","text":"<pre><code># Verify directory structure\ntree dataset/sample_001\n\n# Should show:\n# sample_001/\n# \u2514\u2500\u2500 capture/\n#     \u251c\u2500\u2500 data.raw\n#     \u251c\u2500\u2500 data.hdr\n#     \u251c\u2500\u2500 WHITEREF_data.raw\n#     \u251c\u2500\u2500 WHITEREF_data.hdr\n#     \u251c\u2500\u2500 DARKREF_data.raw\n#     \u2514\u2500\u2500 DARKREF_data.hdr\n</code></pre>"},{"location":"user-guide/data-preparation/#check-header-files","title":"Check Header Files","text":"<pre><code># View header file\ncat dataset/sample_001/capture/data.hdr\n\n# Verify:\n# - samples, lines, bands are positive integers\n# - wavelength list has correct number of entries\n# - data type is valid (1, 2, 4, 5, or 12)\n</code></pre>"},{"location":"user-guide/data-preparation/#test-load","title":"Test Load","text":"<pre><code># Test if Hyperseed can load your data\nhyperseed analyze dataset/sample_001 --output test.csv\n\n# If successful, data is correctly formatted\n</code></pre>"},{"location":"user-guide/data-preparation/#common-data-issues","title":"Common Data Issues","text":""},{"location":"user-guide/data-preparation/#issue-1-missing-reference-files","title":"Issue 1: Missing Reference Files","text":"Error: Could not find white/dark reference <p>Problem: Reference files are missing or incorrectly named.</p> <p>Solution: <pre><code># References must be named:\nWHITEREF_data.raw / WHITEREF_data.hdr\nDARKREF_data.raw / DARKREF_data.hdr\n\n# Check your capture/ directory\nls dataset/sample_001/capture/\n</code></pre></p>"},{"location":"user-guide/data-preparation/#issue-2-dimension-mismatch","title":"Issue 2: Dimension Mismatch","text":"Error: White reference dimensions don't match data <p>Problem: References have different dimensions than main data.</p> <p>Solution: All files must have the same <code>samples</code> and <code>bands</code> values in their headers.</p> <pre><code># Check dimensions in each header\ngrep -E \"samples|bands\" dataset/sample_001/capture/*.hdr\n</code></pre>"},{"location":"user-guide/data-preparation/#issue-3-missing-wavelengths","title":"Issue 3: Missing Wavelengths","text":"Error: No wavelength information in header <p>Problem: Header file doesn't contain wavelength list.</p> <p>Solution: Add wavelength information to <code>.hdr</code> file: <pre><code>wavelength = {\n 1000.0, 1005.0, 1010.0, ...\n}\n</code></pre></p>"},{"location":"user-guide/data-preparation/#issue-4-bad-pixel-issues","title":"Issue 4: Bad Pixel Issues","text":"Warning: Detected bad pixels in reference <p>Problem: Bad/dead pixels in reference images.</p> <p>Solution: Hyperseed automatically interpolates bad pixels. If you have a bad pixel map (<code>.bpr</code>), place it in <code>calibrations/bpr/</code> directory: <pre><code>dataset/sample_001/\n\u2514\u2500\u2500 calibrations/bpr/\n    \u251c\u2500\u2500 bprmap.bpr\n    \u2514\u2500\u2500 bprmap.hdr\n</code></pre></p>"},{"location":"user-guide/data-preparation/#organizing-multiple-datasets","title":"Organizing Multiple Datasets","text":"<p>For batch processing, organize datasets consistently:</p> <pre><code>dataset/\n\u251c\u2500\u2500 sample_001/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u251c\u2500\u2500 data.raw, data.hdr\n\u2502       \u251c\u2500\u2500 WHITEREF_*.raw, WHITEREF_*.hdr\n\u2502       \u2514\u2500\u2500 DARKREF_*.raw, DARKREF_*.hdr\n\u251c\u2500\u2500 sample_002/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 sample_003/\n\u2502   \u2514\u2500\u2500 capture/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre> <p>Then batch process:</p> <pre><code>hyperseed batch dataset/ --output-dir results/\n</code></pre>"},{"location":"user-guide/data-preparation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start: Run your first analysis</li> <li>Preprocessing: Learn about spectral preprocessing</li> <li>Batch Processing: Process multiple datasets</li> <li>Troubleshooting: Solve common problems</li> </ul>"},{"location":"user-guide/preprocessing/","title":"Preprocessing","text":"<p>Spectral preprocessing transforms raw hyperspectral data to improve analysis quality, reduce noise, and enhance relevant features.</p>"},{"location":"user-guide/preprocessing/#overview","title":"Overview","text":"<p>Hyperseed provides comprehensive preprocessing methods for hyperspectral data, including:</p> <ul> <li>SNV (Standard Normal Variate) - Remove multiplicative scatter effects</li> <li>Smoothing - Reduce noise with Savitzky-Golay filtering</li> <li>Baseline Correction - Remove baseline drift</li> <li>Derivatives - Emphasize spectral features</li> <li>MSC (Multiplicative Scatter Correction) - Normalize scatter</li> <li>Detrending - Remove linear trends</li> </ul>"},{"location":"user-guide/preprocessing/#when-to-use-preprocessing","title":"When to Use Preprocessing","text":""},{"location":"user-guide/preprocessing/#for-segmentation","title":"For Segmentation","text":"<p>Minimal Preprocessing Recommended</p> <p>Heavy preprocessing can reduce segmentation quality. Use the <code>minimal</code> preset (smoothing only) for best results.</p> <pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --preprocess minimal\n</code></pre>"},{"location":"user-guide/preprocessing/#for-spectral-analysis","title":"For Spectral Analysis","text":"<p>For analyzing extracted spectra, more preprocessing may improve results:</p> <pre><code>hyperseed analyze dataset/sample_001 \\\n    --output results.csv \\\n    --preprocess standard  # or advanced\n</code></pre>"},{"location":"user-guide/preprocessing/#preprocessing-presets","title":"Preprocessing Presets","text":"<p>Hyperseed provides four preprocessing presets via the <code>--preprocess</code> CLI option or configuration files.</p>"},{"location":"user-guide/preprocessing/#minimal-recommended-for-segmentation","title":"minimal (Recommended for Segmentation)","text":"<p>Enables: Smoothing only</p> <p>Use when: - Performing seed segmentation - Maximizing segmentation accuracy - Keeping spectral features intact</p> <p>Configuration: <pre><code>preprocessing:\n  method: minimal\n</code></pre></p> <p>What it does: - Applies Savitzky-Golay smoothing (window=11, polyorder=3) - Reduces noise while preserving spectral features - No other transformations</p>"},{"location":"user-guide/preprocessing/#standard-balanced","title":"standard (Balanced)","text":"<p>Enables: SNV + Smoothing + Baseline Correction</p> <p>Use when: - Performing general spectral analysis - Balancing noise reduction and feature preservation - Working with spectra that have scatter and baseline issues</p> <p>Configuration: <pre><code>preprocessing:\n  method: standard\n</code></pre></p> <p>What it does: 1. Applies SNV to remove multiplicative scatter 2. Smooths with Savitzky-Golay filter 3. Removes baseline drift with polynomial fitting</p>"},{"location":"user-guide/preprocessing/#advanced-chemometrics","title":"advanced (Chemometrics)","text":"<p>Enables: SNV + Smoothing + Baseline + 2<sup>nd</sup> Derivative + MSC + Detrend</p> <p>Use when: - Performing chemometric analysis - Building classification/regression models - Maximizing spectral transformation for pattern recognition</p> <p>Configuration: <pre><code>preprocessing:\n  method: advanced\n</code></pre></p> <p>What it does: 1. Applies SNV for scatter correction 2. Smooths with Savitzky-Golay filter 3. Removes baseline drift 4. Computes 2<sup>nd</sup> derivative (emphasizes subtle features) 5. Applies MSC for additional scatter normalization 6. Removes linear trends</p> <p>Advanced Preprocessing</p> <p>The <code>advanced</code> preset heavily transforms spectra. Use with caution - may not be suitable for all applications.</p>"},{"location":"user-guide/preprocessing/#none-raw-data","title":"none (Raw Data)","text":"<p>Enables: Nothing</p> <p>Use when: - Analyzing raw, uncalibrated data - Comparing with/without preprocessing - Data is already preprocessed externally</p> <p>Configuration: <pre><code>preprocessing:\n  method: none\n</code></pre></p>"},{"location":"user-guide/preprocessing/#individual-preprocessing-methods","title":"Individual Preprocessing Methods","text":""},{"location":"user-guide/preprocessing/#standard-normal-variate-snv","title":"Standard Normal Variate (SNV)","text":"<p>Purpose: Remove multiplicative scatter effects caused by particle size differences and light scattering.</p> <p>How it works: Each spectrum is centered (zero mean) and scaled (unit variance):</p> <pre><code>SNV(x) = (x - mean(x)) / std(x)\n</code></pre> <p>When to use: - Spectra show scatter-related variations - Working with powder or particulate samples - Preparing data for chemometrics</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  snv: true\n</code></pre></p>"},{"location":"user-guide/preprocessing/#smoothing","title":"Smoothing","text":"<p>Purpose: Reduce random noise while preserving spectral features.</p> <p>Methods available (hardcoded to Savitzky-Golay in presets): - Savitzky-Golay filter (default) - Moving average - Gaussian filter</p> <p>How it works: Fits local polynomials to smooth data points.</p> <p>Parameters: - <code>smoothing_window</code>: Window size (must be odd, range 3-51, default: 11) - <code>smoothing_polyorder</code>: Polynomial order (range 1-5, default: 3)</p> <p>When to use: - Data has high-frequency noise - Before derivative computation - Always (included in all presets except <code>none</code>)</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  smoothing: true\n  smoothing_window: 11\n  smoothing_polyorder: 3\n</code></pre></p> <p>Window Size Selection</p> <ul> <li>Smaller windows (5-9): Less smoothing, preserves detail</li> <li>Medium windows (11-15): Balanced (recommended)</li> <li>Larger windows (17-25): More smoothing, may lose features</li> </ul>"},{"location":"user-guide/preprocessing/#baseline-correction","title":"Baseline Correction","text":"<p>Purpose: Remove baseline drift or offset in spectra caused by instrument or sample effects.</p> <p>Method: Polynomial fitting (hardcoded in presets).</p> <p>How it works: Fits a polynomial to the baseline and subtracts it from the spectrum.</p> <p>Parameters: - <code>baseline_order</code>: Polynomial order (range 1-5, default: 2)   - Order 1: Linear baseline   - Order 2: Quadratic baseline (default)   - Order 3+: Higher-order curves</p> <p>When to use: - Spectra have visible baseline drift - Background fluorescence is present - Offset between spectra needs normalization</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  baseline_correction: true\n  baseline_order: 2\n</code></pre></p>"},{"location":"user-guide/preprocessing/#derivatives","title":"Derivatives","text":"<p>Purpose: Emphasize subtle spectral features and remove baseline effects by computing the rate of change.</p> <p>Orders available: - 0: No derivative (original spectrum) - 1: First derivative (rate of change) - 2: Second derivative (curvature)</p> <p>How it works: Computes derivatives using Savitzky-Golay filter.</p> <p>When to use: - Overlapping peaks need separation - Baseline variations must be eliminated - Building classification models (especially 2<sup>nd</sup> derivative)</p> <p>Trade-offs: - \u2705 Enhances subtle features - \u2705 Removes baseline completely - \u26a0\ufe0f Amplifies noise (smooth first!) - \u26a0\ufe0f Changes interpretation (not absorbance anymore)</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  derivative: 2  # 0, 1, or 2\n</code></pre></p> <p>Derivative + Noise</p> <p>Always smooth before computing derivatives, or noise will be amplified!</p>"},{"location":"user-guide/preprocessing/#multiplicative-scatter-correction-msc","title":"Multiplicative Scatter Correction (MSC)","text":"<p>Purpose: Correct for scatter effects by normalizing all spectra to a reference spectrum.</p> <p>How it works: 1. Computes a reference spectrum (mean of all spectra) 2. Fits each spectrum to the reference via linear regression 3. Corrects using the regression coefficients</p> <p>When to use: - Scatter effects vary between samples - After SNV, if scatter remains - Preparing data for multivariate analysis</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  msc: true\n</code></pre></p> <p>Comparison with SNV: - SNV: Operates on each spectrum independently - MSC: Uses a reference spectrum for correction - Often used together in chemometrics</p>"},{"location":"user-guide/preprocessing/#detrending","title":"Detrending","text":"<p>Purpose: Remove linear trends from spectra.</p> <p>Method: Linear detrending (hardcoded).</p> <p>How it works: Fits and subtracts a straight line from each spectrum.</p> <p>When to use: - Spectra have linear slope - Simple baseline correction needed - Alternative to polynomial baseline correction</p> <p>Configuration: <pre><code>preprocessing:\n  method: custom\n  detrend: true\n</code></pre></p>"},{"location":"user-guide/preprocessing/#custom-preprocessing","title":"Custom Preprocessing","text":"<p>For complete control over preprocessing methods, use <code>method: custom</code> in your configuration:</p> <pre><code>preprocessing:\n  method: custom\n\n  # Enable only what you need\n  snv: true\n  smoothing: true\n  smoothing_window: 15\n  smoothing_polyorder: 3\n  baseline_correction: false\n  derivative: 1\n  msc: false\n  detrend: false\n</code></pre> <p>Then use with analyze:</p> <pre><code>hyperseed analyze dataset/sample_001 \\\n    --config custom_preprocess.yaml\n</code></pre>"},{"location":"user-guide/preprocessing/#method-comparison","title":"Method Comparison","text":"Method Purpose When to Use Avoid When SNV Remove scatter Powder samples, varied particles Need absolute values Smoothing Reduce noise Always (except raw analysis) Over-smoothing loses features Baseline Remove drift Visible baseline issues Baseline is meaningful Derivative Enhance features Overlapping peaks High noise MSC Normalize scatter Multivariate analysis Single spectrum analysis Detrend Remove slope Linear baseline Non-linear baseline"},{"location":"user-guide/preprocessing/#preprocessing-order","title":"Preprocessing Order","text":"<p>When using <code>method: custom</code>, preprocessing is applied in this order:</p> <ol> <li>SNV (if enabled)</li> <li>Smoothing (if enabled)</li> <li>Baseline Correction (if enabled)</li> <li>Derivative (if &gt; 0)</li> <li>MSC (if enabled)</li> <li>Detrending (if enabled)</li> </ol> <p>Order Matters</p> <p>The order of operations is fixed and optimized. Smoothing before derivatives is crucial to avoid noise amplification.</p>"},{"location":"user-guide/preprocessing/#examples","title":"Examples","text":""},{"location":"user-guide/preprocessing/#example-1-segmentation-focus","title":"Example 1: Segmentation Focus","text":"<pre><code># Use minimal preprocessing for best segmentation\nhyperseed analyze dataset/seeds \\\n    --preprocess minimal \\\n    --export-plots\n</code></pre>"},{"location":"user-guide/preprocessing/#example-2-spectral-analysis","title":"Example 2: Spectral Analysis","text":"<pre><code># config.yaml\npreprocessing:\n  method: standard  # SNV + smooth + baseline\n  smoothing_window: 15  # More smoothing\n</code></pre> <pre><code>hyperseed analyze dataset/seeds --config config.yaml\n</code></pre>"},{"location":"user-guide/preprocessing/#example-3-custom-pipeline","title":"Example 3: Custom Pipeline","text":"<pre><code># custom.yaml\npreprocessing:\n  method: custom\n  snv: true           # Remove scatter\n  smoothing: true\n  smoothing_window: 13\n  smoothing_polyorder: 3\n  baseline_correction: true\n  baseline_order: 2\n  derivative: 1       # 1st derivative\n  msc: false\n  detrend: false\n</code></pre> <pre><code>hyperseed analyze dataset/seeds --config custom.yaml\n</code></pre>"},{"location":"user-guide/preprocessing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/preprocessing/#issue-segmentation-quality-decreased-after-preprocessing","title":"Issue: Segmentation quality decreased after preprocessing","text":"<p>Solution: Use <code>minimal</code> preset for segmentation: <pre><code>hyperseed analyze dataset/sample --preprocess minimal\n</code></pre></p>"},{"location":"user-guide/preprocessing/#issue-spectra-still-noisy-after-smoothing","title":"Issue: Spectra still noisy after smoothing","text":"<p>Solution: Increase smoothing window: <pre><code>preprocessing:\n  method: custom\n  smoothing: true\n  smoothing_window: 17  # Larger window\n</code></pre></p>"},{"location":"user-guide/preprocessing/#issue-baseline-correction-over-corrected","title":"Issue: Baseline correction over-corrected","text":"<p>Solution: Reduce polynomial order: <pre><code>preprocessing:\n  baseline_order: 1  # Linear instead of quadratic\n</code></pre></p>"},{"location":"user-guide/preprocessing/#issue-2nd-derivative-too-noisy","title":"Issue: 2<sup>nd</sup> derivative too noisy","text":"<p>Solution: Increase smoothing before derivative: <pre><code>preprocessing:\n  method: custom\n  smoothing: true\n  smoothing_window: 17  # More smoothing\n  derivative: 2\n</code></pre></p>"},{"location":"user-guide/preprocessing/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide: Complete configuration reference</li> <li>API Reference: Programmatic preprocessing</li> <li>CLI Reference: Command-line options</li> </ul>"},{"location":"user-guide/segmentation/","title":"Segmentation","text":"<p>Seed segmentation is the process of detecting and isolating individual seeds in hyperspectral images. Hyperseed provides multiple algorithms optimized for different scenarios.</p>"},{"location":"user-guide/segmentation/#overview","title":"Overview","text":"<p>Segmentation converts hyperspectral imagery into a labeled mask where each seed is assigned a unique ID. This enables:</p> <ul> <li>Spectral extraction from individual seeds</li> <li>Morphological analysis (size, shape, eccentricity)</li> <li>Spatial tracking of seed positions</li> <li>Quality control through outlier removal</li> </ul>"},{"location":"user-guide/segmentation/#when-to-use-each-algorithm","title":"When to Use Each Algorithm","text":""},{"location":"user-guide/segmentation/#threshold-fast-simple","title":"threshold (Fast &amp; Simple)","text":"<p>Best for: - Well-separated seeds with uniform illumination - Quick initial testing - Processing large batches where speed is critical</p> <p>How it works: - Applies global (Otsu) or adaptive thresholding - Labels connected components - Applies morphological cleanup (erosion/dilation)</p> <p>Limitations: - May not separate touching seeds effectively - Sensitive to illumination variations - Less robust than watershed</p> <p>Usage: <pre><code>hyperseed analyze dataset/sample \\\n    --segmentation threshold \\\n    --min-pixels 200\n</code></pre></p>"},{"location":"user-guide/segmentation/#watershed-recommended","title":"watershed (Recommended)","text":"<p>Best for: - Seeds that are touching or close together - Most general use cases - High-quality segmentation</p> <p>How it works: - Computes distance transform from binary mask - Finds local maxima as seed centers - Applies watershed algorithm to separate regions - Effectively \"floods\" from seed centers</p> <p>Advantages: - Separates touching seeds reliably - Robust to minor variations - Good balance of speed and accuracy</p> <p>Usage: <pre><code>hyperseed analyze dataset/sample \\\n    --segmentation watershed \\\n    --min-pixels 200\n</code></pre></p>"},{"location":"user-guide/segmentation/#connected-simple-fast","title":"connected (Simple &amp; Fast)","text":"<p>Best for: - Well-separated seeds with clear gaps - Seeds with consistent size and shape - When watershed is too aggressive</p> <p>How it works: - Binary thresholding with Otsu - Morphological cleanup (closing/opening) - Connected component labeling - Filters by shape (eccentricity &lt; 0.95, solidity &gt; 0.7)</p> <p>Limitations: - Cannot separate touching seeds - May fail with irregular spacing</p> <p>Usage: <pre><code>hyperseed analyze dataset/sample \\\n    --segmentation connected \\\n    --min-pixels 200\n</code></pre></p>"},{"location":"user-guide/segmentation/#combined-most-robust","title":"combined (Most Robust)","text":"<p>Best for: - Critical applications requiring maximum accuracy - Mixed seed arrangements (some touching, some separated) - When you want consensus from multiple methods</p> <p>How it works: - Runs threshold and watershed algorithms - Uses majority voting to create consensus mask - Applies final size filtering - Slower but most robust</p> <p>Trade-offs: - Slowest algorithm (runs multiple methods) - Best accuracy and robustness - Good for challenging images</p> <p>Usage: <pre><code>hyperseed analyze dataset/sample \\\n    --segmentation combined \\\n    --min-pixels 200\n</code></pre></p>"},{"location":"user-guide/segmentation/#algorithm-comparison","title":"Algorithm Comparison","text":"Feature threshold watershed connected combined Speed \u26a1\u26a1\u26a1 Fast \u26a1\u26a1 Medium \u26a1\u26a1\u26a1 Fast \u26a1 Slow Separates touching seeds \u274c No \u2705 Yes \u274c No \u2705 Yes Robustness \u2b50\u2b50 Good \u2b50\u2b50\u2b50 Excellent \u2b50\u2b50 Good \u2b50\u2b50\u2b50\u2b50 Best Illumination tolerance \u26a0\ufe0f Low \u2705 High \u26a0\ufe0f Medium \u2705 High Best use case Quick tests General use Well-separated Critical apps"},{"location":"user-guide/segmentation/#size-filtering","title":"Size Filtering","text":"<p>All algorithms apply size filtering to remove noise and artifacts.</p>"},{"location":"user-guide/segmentation/#min_pixels","title":"min_pixels","text":"<p>Minimum seed size in pixels. Objects smaller than this are removed.</p> <p>Default: 200 pixels</p> <p>How to choose: <pre><code># Small seeds or high-resolution images\nhyperseed analyze dataset/sample --min-pixels 100\n\n# Medium seeds (default, recommended)\nhyperseed analyze dataset/sample --min-pixels 200\n\n# Large seeds or low-resolution images\nhyperseed analyze dataset/sample --min-pixels 300\n</code></pre></p>"},{"location":"user-guide/segmentation/#max_pixels","title":"max_pixels","text":"<p>Maximum seed size in pixels. Objects larger than this are removed.</p> <p>Default: None (no upper limit)</p> <p>Usage: <pre><code># configuration.yaml\nsegmentation:\n  min_pixels: 200\n  max_pixels: 5000  # Remove objects larger than 5000 pixels\n</code></pre></p>"},{"location":"user-guide/segmentation/#morphological-operations","title":"Morphological Operations","text":"<p>Morphological operations clean up segmentation results by filling holes and smoothing boundaries.</p>"},{"location":"user-guide/segmentation/#morphology_operations","title":"morphology_operations","text":"<p>Default: <code>true</code> (enabled)</p> <p>Operations applied: - Closing: Fills small holes within seeds - Opening: Removes small protrusions</p> <p>When to disable: <pre><code>segmentation:\n  morphology_operations: false  # Disable if seeds have irregular shapes\n</code></pre></p>"},{"location":"user-guide/segmentation/#morphology_kernel_size","title":"morphology_kernel_size","text":"<p>Size of the structuring element for morphological operations.</p> <p>Default: 3 pixels Range: 1-21 pixels</p> <p>Effect: - Small (1-3): Minimal cleanup, preserves detail - Medium (3-7): Balanced (recommended) - Large (7-21): Aggressive cleanup, may merge close seeds</p> <pre><code>segmentation:\n  morphology_kernel_size: 5  # More aggressive cleanup\n</code></pre>"},{"location":"user-guide/segmentation/#border-seed-filtering","title":"Border Seed Filtering","text":"<p>Remove seeds that touch the image borders (often incomplete or partially visible).</p>"},{"location":"user-guide/segmentation/#filter_border_seeds","title":"filter_border_seeds","text":"<p>Default: <code>false</code> (disabled)</p> <p>When to enable: - Seeds at edges are incomplete - Want to exclude partial seeds - Analyzing seed distributions (avoid edge bias)</p> <pre><code>segmentation:\n  filter_border_seeds: true\n  border_width: 2  # Pixels from edge\n</code></pre>"},{"location":"user-guide/segmentation/#threshold-method-options","title":"Threshold Method Options","text":"<p>The <code>threshold</code> algorithm supports three thresholding methods:</p>"},{"location":"user-guide/segmentation/#otsu-default","title":"otsu (Default)","text":"<p>Automatic global threshold using Otsu's method.</p> <p>Best for: - Uniform illumination - Clear seed/background separation - Most common use case</p> <pre><code>segmentation:\n  algorithm: threshold\n  threshold_method: otsu\n</code></pre>"},{"location":"user-guide/segmentation/#adaptive","title":"adaptive","text":"<p>Local adaptive thresholding for uneven illumination.</p> <p>Best for: - Non-uniform lighting - Gradients across image - Shadows present</p> <pre><code>segmentation:\n  algorithm: threshold\n  threshold_method: adaptive\n</code></pre>"},{"location":"user-guide/segmentation/#manual","title":"manual","text":"<p>Requires explicit threshold value (not exposed in CLI, API only).</p>"},{"location":"user-guide/segmentation/#outlier-removal","title":"Outlier Removal","text":"<p>Automatic outlier removal eliminates reference objects, debris, and anomalies.</p>"},{"location":"user-guide/segmentation/#why-remove-outliers","title":"Why Remove Outliers?","text":"<p>Hyperspectral seed datasets often contain:</p> <ul> <li>Calibration targets (white/dark references in view)</li> <li>Reference objects (rulers, labels, markers)</li> <li>Debris (dust, chaff, broken seeds)</li> <li>Anomalies (clumped seeds, imaging artifacts)</li> </ul> <p>Outlier removal automatically filters these without manual intervention.</p>"},{"location":"user-guide/segmentation/#three-step-process","title":"Three-Step Process","text":""},{"location":"user-guide/segmentation/#step-1-absolute-area-bounds","title":"Step 1: Absolute Area Bounds","text":"<p>Hard thresholds that always apply.</p> <pre><code>segmentation:\n  outlier_min_area: 50    # Remove anything &lt; 50 pixels\n  outlier_max_area: 2000  # Remove anything &gt; 2000 pixels\n</code></pre> <p>Use case: Remove obviously too-small (debris) or too-large (reference targets) objects.</p>"},{"location":"user-guide/segmentation/#step-2-iqr-based-filtering","title":"Step 2: IQR-Based Filtering","text":"<p>Statistical outlier detection using Interquartile Range.</p> <p>How it works: 1. Calculate Q1 (25<sup>th</sup> percentile) and Q3 (75<sup>th</sup> percentile) of seed areas 2. Compute IQR = Q3 - Q1 3. Define bounds:    - Lower bound = Q1 - (iqr_lower \u00d7 IQR)    - Upper bound = Q3 + (iqr_upper \u00d7 IQR) 4. Remove seeds outside bounds</p> <p>Configuration: <pre><code>segmentation:\n  outlier_iqr_lower: 1.5  # Stricter lower bound\n  outlier_iqr_upper: 3.0  # Looser upper bound (large outliers more common)\n</code></pre></p> <p>Why asymmetric? Large outliers (calibration targets, rulers) are more common than small outliers, so the upper multiplier is larger.</p>"},{"location":"user-guide/segmentation/#step-3-shape-based-filtering-optional","title":"Step 3: Shape-Based Filtering (Optional)","text":"<p>Filter by shape properties (disabled by default).</p> <pre><code>segmentation:\n  use_shape_filtering: true\n  outlier_eccentricity: 0.95  # Max elongation (0=circle, 1=line)\n  outlier_solidity: 0.7       # Min regularity (area/convex_hull)\n</code></pre> <p>When to enable: - Seeds should be round or oval - Want to exclude elongated debris - Reject irregularly shaped clumps</p> <p>Examples: - Eccentricity 0.5 = moderately oval seed \u2705 - Eccentricity 0.98 = elongated debris \u274c - Solidity 0.85 = solid seed \u2705 - Solidity 0.55 = irregular clump \u274c</p>"},{"location":"user-guide/segmentation/#disabling-outlier-removal","title":"Disabling Outlier Removal","text":"<pre><code>hyperseed analyze dataset/sample --no-outlier-removal\n</code></pre> <pre><code>segmentation:\n  remove_outliers: false\n</code></pre> <p>When to disable: - All objects in image are seeds - Want to manually inspect all detections - Performing custom filtering later</p>"},{"location":"user-guide/segmentation/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"user-guide/segmentation/#example-1-default-recommended","title":"Example 1: Default (Recommended)","text":"<pre><code>segmentation:\n  algorithm: watershed\n  min_pixels: 200\n  max_pixels: null\n  reject_overlapping: true\n  threshold_method: otsu\n  morphology_operations: true\n  morphology_kernel_size: 3\n  filter_border_seeds: false\n  remove_outliers: true\n  outlier_min_area: 50\n  outlier_max_area: 2000\n  outlier_iqr_lower: 1.5\n  outlier_iqr_upper: 3.0\n  use_shape_filtering: false\n</code></pre>"},{"location":"user-guide/segmentation/#example-2-strict-outlier-removal","title":"Example 2: Strict Outlier Removal","text":"<pre><code>segmentation:\n  algorithm: watershed\n  min_pixels: 200\n  remove_outliers: true\n  outlier_min_area: 100        # Larger minimum\n  outlier_max_area: 1500       # Smaller maximum\n  outlier_iqr_lower: 1.0       # Stricter IQR\n  outlier_iqr_upper: 2.0\n  use_shape_filtering: true    # Enable shape filtering\n  outlier_eccentricity: 0.90   # Reject more elongated seeds\n  outlier_solidity: 0.75       # Require more regular shapes\n</code></pre>"},{"location":"user-guide/segmentation/#example-3-fast-processing","title":"Example 3: Fast Processing","text":"<pre><code>segmentation:\n  algorithm: threshold         # Fastest algorithm\n  threshold_method: otsu\n  min_pixels: 200\n  morphology_operations: false # Skip cleanup for speed\n  remove_outliers: false       # Skip outlier detection\n</code></pre>"},{"location":"user-guide/segmentation/#example-4-maximum-accuracy","title":"Example 4: Maximum Accuracy","text":"<pre><code>segmentation:\n  algorithm: combined          # Most robust\n  min_pixels: 150\n  max_pixels: 5000\n  morphology_operations: true\n  morphology_kernel_size: 5    # More cleanup\n  filter_border_seeds: true    # Remove edge seeds\n  remove_outliers: true\n  use_shape_filtering: true    # All filtering enabled\n</code></pre>"},{"location":"user-guide/segmentation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/segmentation/#issue-seeds-not-detected","title":"Issue: Seeds not detected","text":"<p>Possible causes: - <code>min_pixels</code> too high - Preprocessing removed too much signal - Poor illumination/contrast</p> <p>Solutions: <pre><code># Lower min_pixels threshold\nhyperseed analyze dataset/sample --min-pixels 100\n\n# Try different algorithm\nhyperseed analyze dataset/sample --segmentation combined\n\n# Use minimal preprocessing\nhyperseed analyze dataset/sample --preprocess minimal\n</code></pre></p>"},{"location":"user-guide/segmentation/#issue-touching-seeds-not-separated","title":"Issue: Touching seeds not separated","text":"<p>Solutions: <pre><code># Use watershed algorithm (best for separation)\nhyperseed analyze dataset/sample --segmentation watershed\n\n# Try combined method\nhyperseed analyze dataset/sample --segmentation combined\n</code></pre></p>"},{"location":"user-guide/segmentation/#issue-too-many-small-detections-noise","title":"Issue: Too many small detections (noise)","text":"<p>Solutions: <pre><code># Increase min_pixels\nhyperseed analyze dataset/sample --min-pixels 300\n\n# Enable outlier removal (should be default)\nhyperseed analyze dataset/sample  # outlier removal is on by default\n\n# Increase morphology cleanup\n</code></pre></p> <pre><code>segmentation:\n  morphology_kernel_size: 7\n</code></pre>"},{"location":"user-guide/segmentation/#issue-reference-objects-detected-as-seeds","title":"Issue: Reference objects detected as seeds","text":"<p>Solution: Enable outlier removal with appropriate thresholds:</p> <pre><code>segmentation:\n  remove_outliers: true\n  outlier_max_area: 1500  # Adjust based on reference object size\n</code></pre>"},{"location":"user-guide/segmentation/#issue-over-segmentation-seeds-split-into-multiple-parts","title":"Issue: Over-segmentation (seeds split into multiple parts)","text":"<p>Possible causes: - Morphology operations too aggressive - Algorithm too sensitive</p> <p>Solutions: <pre><code>segmentation:\n  morphology_operations: false  # Disable cleanup\n  # Or reduce kernel size\n  morphology_kernel_size: 1\n</code></pre></p> <p>Try less aggressive algorithm: <pre><code>hyperseed analyze dataset/sample --segmentation connected\n</code></pre></p>"},{"location":"user-guide/segmentation/#workflow-recommendations","title":"Workflow Recommendations","text":""},{"location":"user-guide/segmentation/#1-start-with-defaults","title":"1. Start with defaults","text":"<pre><code>hyperseed analyze dataset/sample \\\n    --output results.csv \\\n    --export-plots\n</code></pre> <p>Review the segmentation visualization to assess quality.</p>"},{"location":"user-guide/segmentation/#2-adjust-min_pixels-if-needed","title":"2. Adjust min_pixels if needed","text":"<pre><code># If too many small detections\nhyperseed analyze dataset/sample --min-pixels 300\n\n# If seeds not detected\nhyperseed analyze dataset/sample --min-pixels 100\n</code></pre>"},{"location":"user-guide/segmentation/#3-try-different-algorithms","title":"3. Try different algorithms","text":"<pre><code># If seeds are touching\nhyperseed analyze dataset/sample --segmentation watershed\n\n# If watershed over-separates\nhyperseed analyze dataset/sample --segmentation connected\n\n# If unsure\nhyperseed analyze dataset/sample --segmentation combined\n</code></pre>"},{"location":"user-guide/segmentation/#4-fine-tune-outlier-removal","title":"4. Fine-tune outlier removal","text":"<p>Create custom configuration file:</p> <pre><code># config.yaml\nsegmentation:\n  algorithm: watershed\n  min_pixels: 200\n  remove_outliers: true\n  outlier_min_area: 75      # Adjust based on your seeds\n  outlier_max_area: 1800\n  outlier_iqr_lower: 1.5\n  outlier_iqr_upper: 2.5    # Stricter upper bound\n</code></pre> <pre><code>hyperseed analyze dataset/sample --config config.yaml\n</code></pre>"},{"location":"user-guide/segmentation/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide: Complete parameter reference</li> <li>API Reference: Programmatic segmentation</li> <li>CLI Reference: segment command documentation</li> </ul>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and solutions for Hyperseed.</p>"},{"location":"user-guide/troubleshooting/#installation-issues","title":"Installation Issues","text":"<p>See Installation Troubleshooting</p>"},{"location":"user-guide/troubleshooting/#data-loading-issues","title":"Data Loading Issues","text":"<p>See Data Preparation</p>"},{"location":"user-guide/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check GitHub Issues for similar problems</li> <li>Create a new issue with:<ul> <li>Your OS and Python version</li> <li>Complete error message</li> <li>Minimal example to reproduce the issue</li> </ul> </li> </ol>"}]}